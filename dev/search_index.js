var documenterSearchIndex = {"docs":
[{"location":"EasyModels/#Easy-NODE-and-UDE","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"","category":"section"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"EasyNODE and EasyUDE provide a quick, simple alternative to the other model constructors featured by UniversalDiffEq.jl. They each return pre-trained models, in which neural networks are kept to 1 hidden layer. The models are trained using the gradient_descent! function.","category":"page"},{"location":"EasyModels/#EasyNODE-constructors:","page":"Easy NODE and UDE","title":"EasyNODE constructors:","text":"","category":"section"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"EasyNODE(data,X;kwargs ... )\nEasyNODE(data;kwargs ... )","category":"page"},{"location":"EasyModels/#UniversalDiffEq.EasyNODE-Tuple{Any, Any}-EasyModels","page":"Easy NODE and UDE","title":"UniversalDiffEq.EasyNODE","text":"EasyNODE(data,X;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for values of time not included in the data frame. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"EasyModels/#UniversalDiffEq.EasyNODE-Tuple{Any}-EasyModels","page":"Easy NODE and UDE","title":"UniversalDiffEq.EasyNODE","text":"EasyNODE(data;kwargs ... )\n\nConstructs a pretrained continuous time model for the data set data using a single layer neural network to represent the systems dynamics. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"Creating an UDE constructor using the EasyNODE function is equivalent to creating it using the NODE function and running gradient_descent!.","category":"page"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"easy_model = EasyNODE(data)\n\n#Is equivalent to running\nmodel = NODE(data)\ngradient_descent!(model)","category":"page"},{"location":"EasyModels/#EasyUDE-constructors:","page":"Easy NODE and UDE","title":"EasyUDE constructors:","text":"","category":"section"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"EasyUDE(data,known_dynamics!,initial_parameters;kwargs ... )\nEasyUDE(data::DataFrame,X,known_dynamics!::Function,initial_parameters;kwargs ... )","category":"page"},{"location":"EasyModels/#UniversalDiffEq.EasyUDE-Tuple{Any, Any, Any}-EasyModels","page":"Easy NODE and UDE","title":"UniversalDiffEq.EasyUDE","text":"EasyUDE(data,derivs!,initial_parameters;kwargs ... )\n\nConstructs a pretrained UDE model for the data set data  based on user defined derivatives derivs. An initial guess of model parameters are supplied with the initial_parameters argument. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"EasyModels/#UniversalDiffEq.EasyUDE-Tuple{DataFrame, Any, Function, Any}-EasyModels","page":"Easy NODE and UDE","title":"UniversalDiffEq.EasyUDE","text":"EasyUDE(data::DataFrame,X,derivs!::Function,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame.  When X is provided the derivs function must have the form derivs!(du,u,x,p,t) where x is a vector with the value of the covariates at time t. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"Unlike EasyNODE, running EasyUDE is not equivalent to running CustomDerivatives and gradient_descent!. EasyUDE creates UDE constructors with a continuous process model of the form","category":"page"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"fracdxdt = NN(xwb) + f(xa)","category":"page"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"where f corresponds to the known_dynamics! argument, and a the initial_parameters argument in EasyUDE.","category":"page"},{"location":"EasyModels/","page":"Easy NODE and UDE","title":"Easy NODE and UDE","text":"function known_dynamics!(du,u,parameters,t)\n    du .= parameters.a.*u .+ parameters.b #some function here\n    return du\nend\ninitial_parameters = (a = 1, b = 0.1)\neasy_model = EasyUDE(data,known_dynamics!,initial_parameters)\n\n#Is equivalent to running\nusing Lux, Random\ndims_in = 1\nhidden_units = 10\nnonlinearity = tanh\ndims_out = 1\nNN = Lux.Chain(Lux.Dense(dims_in,hidden_units,nonlinearity),\n                Lux.Dense(hidden_units,dims_out))\n\nrng = Random.default_rng() \nNNparameters, states = Lux.setup(rng,NN) \n\nfunction derivs!\n    C, states = NN(u,p.NN,states)\n    du .= C .+ a*u .+ b\n    return du\nend\ninitial_parameters = (a = 1, b = 0.1)\nmodel = CustomDerivatives(data,derivs!,initial_parameters)","category":"page"},{"location":"NutsAndBolts/#UDE-model-construction","page":"UDE model construction","title":"UDE model construction","text":"","category":"section"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"Some users may wish to access elements of a fitted model directly to create custom model visualizations, performance tests, or other applications not foreseen by the developers. To this end, we provide documentation of classes (Julia mutable structs) used by UniversalDiffEq.jl to build the NODE and UDE objects. The package is built around the UDE class which stores the data used to fit a model and instances of six submodel classes used to define the full model. ","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"UniversalDiffEq.jl uses a state-space modeling framework to define and fit NODE and UDE models. State-space models are a class of time series models that describe time series data with a process model that describes the dynamics of a sequence of unobserved state variables u_t, as well as an observation model that defines the relationship between the state variables u_t and the observations x_t.  The process model f predicts value of the state variables one step ahead","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"hatu_t+Delta t  = f(u_t t Delta t theta_proc)","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"where Delta t is the time span between observations, and theta_proc is the process model parameters. The observation model maps from the state variables u_t to the observations","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"x_t = h(u_t t Delta t theta_obs)","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"where theta_obs is the observation model parameters. In addition to these primary functions, both the observation model and process model have a loss function to measure the accuracy of their predictions. This can be thought of as the likelihood models used in generalized linear models. For example, we can measure the performance of the process model with a normal likelihood","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"L(hatu_tu_t) = frac1sigma sqrt2pi e^-frac12(frachatu_t-u_tsigma)^2","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"where sigma is the variance of the prediction errors. Although in principle any likelihood can be used, we use the mean squared error in our base model specification. ","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"The UDE models also include submodels to regularize the process and observation models. The regularization models are functions of the model parameters that add to the loss function. The regularization models are in effect priors on the model parameters. Regularization is especially important for neural network models to reduce overfitting to training data and make the models more generalizable. For example, our default model constructors apply L2 regularization to neural network parameters in the process model","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"R(theta_proc) = omega theta_proc_L2","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"where omega is the weight given to regularization in the overall loss function. ","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"These six model components are all combined into one loss functions used to fit the UDE models","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"L(utheta_proctheta_obsx) = sum_t =1^T L_obs(x_th(u_ttheta_obs)sigma_obs) + sum_t=2^T L_proc(u_tf(u_t-1theta_proc)sigma_proc) + R_obs(theta_obs) + R_proc(theta_proc)","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"where the sigma_i are parameters for the loss functions and the theta_i are parameters for the prediction functions. ","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"The UDE object combines the observation and process models and their respective loss and regularization models into one larger model object along with the data used to fit the model.","category":"page"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"UDE","category":"page"},{"location":"NutsAndBolts/#UniversalDiffEq.UDE-NutsAndBolts","page":"UDE model construction","title":"UniversalDiffEq.UDE","text":"UDE\n\nBasic data structure used to the model structure, parameters and data for UDE and NODE models.  ...\n\nElements\n\ntimes: a vector of times for each observation\ndata: a matrix of observaitons at each time point\nX: a DataFrame with any covariates used by the model\ndata_frame: a DataFrame with columns for the time of each observation and values of the state variables\nparameters: a ComponentArray that stores model parameters\nloss_function: the loss function used to fit the model\nprocess_model: a Julia mutable struct used to define model predictions \nprocess_loss: a Julia mutable struct used to measure the performance of model predictions\nobservation_model: a Julia mutable struct used to predict observaitons given state variable estimates\nobservaiton_loss: a Julia mutable struct used to measure the performance of the observation model\nprocess_regularization: a Julia mutable struct used to store data needed for process model regularization\nobservation_regularization: a Julia mutable struct used to store data needed for observation model regularization\nconstructor: A function that initializes a UDE model with identical structure.\ntimecolumnname: A string with the name of the column used for \nweights \nvariablecolumnname \nvaluecolumnname\n\n...\n\n\n\n\n\n","category":"type"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"UniversalDiffEq.ProcessModel","category":"page"},{"location":"NutsAndBolts/#UniversalDiffEq.ProcessModel-NutsAndBolts","page":"UDE model construction","title":"UniversalDiffEq.ProcessModel","text":"ProcessModel\n\nA Julia mutable struct that stores the functions and parameters for the process model.  ...\n\nElements\n\nparameters: ComponentArray\npredict: Function the predict one time step ahead\nforecast: Function, a modified version of predict to improve performance when extrapolating\ncovariates: Function that returns the value of the covariates at each point in time. \n\n...\n\n\n\n\n\n","category":"type"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"UniversalDiffEq.LossFunction","category":"page"},{"location":"NutsAndBolts/#UniversalDiffEq.LossFunction-NutsAndBolts","page":"UDE model construction","title":"UniversalDiffEq.LossFunction","text":"LossFunction\n\nA Julia mutable struct that stores the loss function and parameters. ...\n\nElements\n\nparameters: ComponentArray\nloss: Function \n\n...\n\n\n\n\n\n","category":"type"},{"location":"NutsAndBolts/","page":"UDE model construction","title":"UDE model construction","text":"UniversalDiffEq.Regularization  ","category":"page"},{"location":"NutsAndBolts/#UniversalDiffEq.Regularization-NutsAndBolts","page":"UDE model construction","title":"UniversalDiffEq.Regularization","text":"Regularization\n\nA Julia mutable struct that stores the loss function and parameters. ...\n\nElements\n\nreg_parameters: ComponentArray\nloss: Function \n\n...\n\n\n\n\n\n","category":"type"},{"location":"CrossValidation/#Cross-validation","page":"Cross validation","title":"Cross validation","text":"","category":"section"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"Cross validation approximates the performance of a trained model on new data. These methods are useful for validating the performance of UDE models and for choosing between alternative models. UniversalDiffEq.jl supports two Cross validation methods, leave future out cross validation and k-fold cross validation. These two methods are based on the same assumption, we can approximate the models perforance on new data by testing it on data left out of the existing data set. Leave future out and k-fold cross validation differ in how these dat sets are constructed. Leave future out cross validation sequentially leaves data off the end of the time sereis data set with the goal of approximating the models preformance forecasting new observaitons. k-fold cross validation approximates the models ability to explain the historical dynamics of the time series by leaving block of consequtive observations out of the middel data set. Each method constructes several training and testing data sets to reduce the effect of random variation on the estiamtes of model perforamnce.  ","category":"page"},{"location":"CrossValidation/#K-fold-cross-validation","page":"Cross validation","title":"K-fold cross validation","text":"","category":"section"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"k-fold cross validation breaks the data set up into k equally sized blocks of sequential observations. The algorithm trains the model on all but one of the blocks which is used as the testing data set and repeates this procedure leaving each block out one at a time. ","category":"page"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"The models performance is evalauted predicting one time step ahead in the testing data set. The initial points for the preditions are estimated using a particle filter algorithm, described in detail below. The forecasts are calcualted starting from the estiamte of the state variable estiamted by the particle filter and compared to the observed data point one step into the future.  ","category":"page"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"cross_validation_kfold(model::UDE; kwagrs...)","category":"page"},{"location":"CrossValidation/#UniversalDiffEq.cross_validation_kfold-Tuple{UDE}-CrossValidation","page":"Cross validation","title":"UniversalDiffEq.cross_validation_kfold","text":"crossvalidationkfold(model::UDE; kwagrs...)\n\nThis funciton approximates model performance on out of sample data by leaving blocks of consequtive observaitons out of the training data. The model is trained on the remiaining observations and the and the one step ahead prediction accuracy is calcualted on the testing data set. This procedure is repeated k times.   ...\n\nArguments\n\nk = 10 - the number of testing data sets BFGS = false - weather or not to train the models with the BFGS algorithm  stepsize = 0.05 - the step size for the first round of gradient descent optimization  maxiter = 500 - the number of iterations for the first round of gradinet descent  stepsize2 = 0.05 - the step size for the second round of gradient descent  maxiter2 = 500 - the number of iterations for the second round of gradient descent N = 1000 - the number of particle to use in the particle filter algorithm that estiamtes the states in the out of sample data  nugget = 10^-10 - a small number to added variance terms in the particle filter algorith to improve numerical stability ...\n\n\n\n\n\n","category":"method"},{"location":"CrossValidation/#Leave-future-out-cross-validation","page":"Cross validation","title":"Leave future out cross validation","text":"","category":"section"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"Leave future out cross validation creates training data sets by leaving observation off of the end of the data set. The model performacne is calculated by forecasting over the length of the data set and and the forecasting skill is quatified by the squared error between the model predictions and the testing data. The process is repreated on new testing data sets constructed by reoving observaitons from the end of the data set. ","category":"page"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"leave_future_out_cv(model::UDE; kwargs ...)","category":"page"},{"location":"CrossValidation/#UniversalDiffEq.leave_future_out_cv-Tuple{UDE}-CrossValidation","page":"Cross validation","title":"UniversalDiffEq.leave_future_out_cv","text":"leave_future_out_cv(model::UDE; kwargs ...)\n\nRuns K fold leave future out cross validation and returns the mean squared forecasting error and a plot to visualize the model fits.\n\n...\n\nArguments\n\nmodel - the UDE model to test forecastlength = 5 - The number of data points to forecast forecastnumber = 10 - The number of trainin gnad testing data sets to create spacing = 2 - The number of data points to skip between the end of each new triaining data set BFGS=false - use BFGS algorithm to train the model stepsize = 0.05 - step size for first run of the ADAM algorithm  maxiter = 500 - maximum iterations for first trial of ADAM stepsize2 = 0.01 - step size for second iteration of ADAM, only used of BFGS is false maxiter2 = 500 - step size for second iteration of ADAM, only used of BFGS is false ...\n\n\n\n\n\n","category":"method"},{"location":"CrossValidation/#Particle-filter-algorithm","page":"Cross validation","title":"Particle filter algorithm","text":"","category":"section"},{"location":"CrossValidation/","page":"Cross validation","title":"Cross validation","text":"Particel filter algorithms are a method for estimating the vaue of unobserved state variables given a time series and state space model. The Particle filter algorithms used in the cross validation procedures use the trained UDE model for the deterministic components of the process and observation models. The process and observaiton errors are estiamted by calcualting the total variance of the process and observation residuals sigma_total. The total variacne is then partitioned between process and observaiton error to match the ratio between the process and observaiton weights used to train the model. The full details of this algorithm are discussed in the supporting information to Buckner et al. 2024. ","category":"page"},{"location":"Models/#Model-Constructors","page":"Model Constructors","title":"Model Constructors","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.jl provides a set of functions to construct universal differential equations UDEs and neural ordinary differential equations NODEs with varying levels of customization. The model constructors all require the data to be passed using a DataFrame object from the DataFrames.jl library. The data frame should be organized with one column for time and one column for each dimension of the observations. The name of the column for time is passed using a key word argument time_column_name that has a defualt value \"t\".","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Table:Example dataset with two state variables","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"t y_1 y_2\n0.1 0.0 -1.1\n0.2 0.01 -0.9\n0.5 0.51 -1.05","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Currently, missing data are not directly supported, but irregular intervals between time points are allowed.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Each constructor function requires additional inputs to specify the model structure. For example, the CustomDerivatives function requires the user to supply the known functional forms through the derives! argument. The subsection for each model type describes these arguments in detail.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Finally, the constructor functions share a set of keyword arguments (kwargs) used to tune the model fitting procedure. These control the weights given to the process model, observation model, and regularization in the loss function. Larger values of the regularization weight limit the complexity of the relationships learned by the neural network to reduce the likelihood of overfitting. The observation weight controls how closely the estimated states u_t match the observations y_t; smaller values of the observation weight correspond to datasets with larger amounts of observation error.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"proc_weight=1.0 : The weight given to the model predictions in the loss function\nobs_weight=1.0 : The weight given to the state estimates in the loss function\nreg_weight=0.0 : The weight given to regularization in the loss function","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"In addition to these weighting parameters, the keyword argument l controls how far the model will extrapolate beyond the observed data before reverting to a default value extrap_rho when forecasting.","category":"page"},{"location":"Models/#NODEs-(Nonparametric-universal-dynamic-equations)","page":"Model Constructors","title":"NODEs (Nonparametric universal dynamic equations)","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.jl has two functions to build time series models that use a neural network to learn the dynamics of a time series. The function NODE builds a continuous-time UDE with a neural network representing the right-hand side of the differential equation","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"   fracdudt = NN(uwb)","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"The function NNDE (neural network difference equation) constructs a discrete-time model with a neural network on the right-hand side","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"   x_t+1 = x_t + NN(x_t)","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.NODE(data;kwargs ... )\nUniversalDiffEq.NNDE(data;kwargs ...)","category":"page"},{"location":"Models/#UniversalDiffEq.NODE-Tuple{Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.NODE","text":"NODE(data;kwargs ... )\n\nConstructs a nonparametric continuous time model for the data set data using a single layer neural network to represent the systems dynamics. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".    \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"Models/#UniversalDiffEq.NNDE-Tuple{Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.NNDE","text":"NNDE(data;kwargs ...)\n\nConstructs a nonparametric discrete time model for the data set data using a single layer neural network to represent the systems dynamics. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Covariates can be included in the model by supplying a second data frame, X. This data frame must have the same column name for a time as the primary dataset, but the time points do not need to match because the values of the covariates between time points included in the data frame X are interpolated using a linear spline.  The NODE and NNDE functions will append the value of the covariates at each point in time to the neural network inputs","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"   fracdxdt = NN(xX(t)wb) \n   x_t+1 = x_t + NN(x_t X(t))","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.NODE(data,X;kwargs ... )","category":"page"},{"location":"Models/#UniversalDiffEq.NODE-Tuple{Any, Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.NODE","text":"NODE(data,X;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for values of time not included in the data frame. \n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Long-format data sets can be used to define models with multiple covariates that have different sampling frequencies. If a long-format dataset is provided, the user must specify which column contains the variable names and which column contains the values of the variables using the variable_column_name and value_column_name keywords. In the example below, the variable column name is \"variable,\" and the value column name is \"value.\"","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Table:Example covariate data in long format","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"t variable value\n1.0 X_1 -1.1\n2.0 X_1 -0.9\n3.0 X_1 -1.05\n... ... ...\n1.0 X_2 3.0\n2.0 X_2 0.95\n4.0 X_2 -1.25","category":"page"},{"location":"Models/#Customizing-universal-dynamic-equations","page":"Model Constructors","title":"Customizing universal dynamic equations","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"The CustomDerivatives and CustomDifference functions can be used to build models that combine neural networks and known functional forms. These functions take user-defined models, construct a loss function, and provide access to the model fitting and testing functions provided by UniversalDiffEq.jl.","category":"page"},{"location":"Models/#Continuous-time-models","page":"Model Constructors","title":"Continuous time models","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"The CustomDerivatives function builds SS-UDE models based on a user-defined function derivs!(du,u,p,t), which updates the vector du with the right-hand side of a differential equation evaluated at time t in state u given parameters p. The function also needs an initial guess at the model parameters, specified by a NamedTuple initial_parameters","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.CustomDerivatives(data,derivs!,initial_parameters;kwargs ... )","category":"page"},{"location":"Models/#UniversalDiffEq.CustomDerivatives-Tuple{Any, Any, Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.CustomDerivatives","text":"CustomDerivatives(data,derivs!,initial_parameters;kwargs ... )\n\nConstructs a UDE model for the data set data  based on user defined derivatives derivs. An initial guess of model parameters are supplied with the initial_parameters argument. \n\n...\n\nArguments\n\ndata: a DataFrame object with the time of observations in a column labeled t and the remaining columns the value of the state variables at each time point. \nderivs: a Function of the form derivs!(du,u,p,t) where u is the value of the state variables, p are the model parameters, t is time, and du is updated with the value of the derivatives\ninit_parameters: A NamedTuple with the model parameters. Neural network parameters must be listed under the key NN.\n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"Models/#Example","page":"Model Constructors","title":"Example","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"The following block of code shows how to build a UDE model based on the Lotka-Volterra predator-prey model where the growth rate of the prey r, mortality rate of the predator m, and conversion efficiency theta are estimated, and the predation rate is described by a neural network NN","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"fracdNdt = rN - NN(NP) \nfracdPdt = theta NN(NP) - mP","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"To implement the model, we define the neural network and initialize its parameters using the Lux.Chain and  Lux.setup functions.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"using Lux\n# Build the neural network with Lux.Chain\ndims_in = 2\nhidden_units = 10\nnonlinearity = tanh\ndims_out = 1\nNN = Lux.Chain(Lux.Dense(dims_in,hidden_units,nonlinearity),Lux.Dense(hidden_units,dims_out))\n\n# initialize the neural network states and parameters\nusing Random\nrng = Random.default_rng()\nNNparameters, states = Lux.setup(rng,NN)","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"With the neural network in hand, we define the derivatives of the differential equations model using standard Julia syntax. The derivs function first evaluates the neural network given the abundance of the predators and prey u. The neural network function NN requires three arguments: the state variables u, the network parameters, and the network states. In this example, we store the model parameters in a named tuple p, and we access the neural network parameters with the NN. We access the other model parameters using keys corresponding to their respective names.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"function lotka_volterra_derivs!(du,u,p,t)\n    C, states = NN(u,p.NN,states)\n    du[1] = p.r*u[1] - C[1]\n    du[2] = p.theta*C[1] -p.m*u[2]\nend","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Finally, we can define the initial parameters as a NamedTuple and build the model using the CustomDerivatives function.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"using UniversalDiffEq\ninitial_parameters = (NN = NNparameters, r = 1.0, m = 0.5, theta = 0.5)\nmodel = CustomDerivatives(data,lotka_volterra_derivs!,initial_parameters)","category":"page"},{"location":"Models/#Discrete-time-model","page":"Model Constructors","title":"Discrete time model","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Discrete-time models are constructed similarly to continuous-time models. The user provides a data set, initial parameter values, and the right-hand side of a discrete-time equation with the function step ","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"U_t+1 = textstep(u_ttp)","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"The function step(u,t,p) takes three arguments: the value of the state variables u, time t, and model parameters p.","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.CustomDifference(data,step,initial_parameters;kwargs ...)","category":"page"},{"location":"Models/#UniversalDiffEq.CustomDifference-Tuple{Any, Any, Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.CustomDifference","text":"CustomDifference(data,step,initial_parameters;kwrags...)\n\nConstructs a UDE model for the data set data based on user defined difference equation step. An initial guess of model parameters are supplied with the initial_parameters argument. ...\n\nArguments\n\ndata: a DataFrame object with the time of observations in a column labeled t and the remaining columns the value of the state variables at each time point. \nstep: a Function of the form step(u,t,p) where u is the value of the state variables, p are the model parameters.\ninit_parameters: A NamedTuple with the model parameters. Neural network parameters must be listed under the key NN.\n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"Models/#Adding-covariates","page":"Model Constructors","title":"Adding covariates","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Covariates are added to UDE models by passing a data frame X to the constructor function. The covariates must also be added as an argument to the derivs! function, which has the new form derivs!(du,u,X,p,t), where the third argument X is a vector with the value of each covariat at time t","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.CustomDerivatives(data::DataFrame,X::DataFrame,derivs!::Function,initial_parameters;kwargs ... )","category":"page"},{"location":"Models/#UniversalDiffEq.CustomDerivatives-Tuple{DataFrame, DataFrame, Function, Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.CustomDerivatives","text":"CustomDerivatives(data::DataFrame,X::DataFrame,derivs!::Function,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame. \n\nWhen X is provided the derivs function must have the form derivs!(du,u,x,p,t) where x is a vector with the value of the covariates at time t. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Covariates can  be added to discrete time models in the same way. In this case tThe step function should have four arguments step(u,X,t,p).","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.CustomDifference(data::DataFrame,X,step,initial_parameters;kwargs ... )","category":"page"},{"location":"Models/#UniversalDiffEq.CustomDifference-Tuple{DataFrame, Any, Any, Any}-Models","page":"Model Constructors","title":"UniversalDiffEq.CustomDifference","text":"CustomDifference(data::DataFrame,X,step,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame. \n\nWhen X is provided the step function must have the form step(u,x,t,p) where x is a vector with the value of the covariates at time t. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"Models/#Example-2","page":"Model Constructors","title":"Example","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"We extend the Lotka-Volterra equations defined in the prior example to  incorporate a covariate X that influences the abundance of predators and prey. We model this effect with linear coefficients beta_N and beta_P","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"fracdNdt = rN - NN(NP) + beta_N N \nfracdPdt = theta NN(NP) - mP + beta_P P","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"# set up neural network\nusing Lux\ndims_in = 2\nhidden_units = 10\nnonlinearity = tanh\ndims_out = 1\nNN = Lux.Chain(Lux.Dense(dims_in,hidden_units,nonlinearity),Lux.Dense(hidden_units,dims_out))\n\n# initialize parameters\nusing Random\nrng = Random.default_rng()\nNNparameters, NNstates = Lux.setup(rng,NN)\n\nfunction derivs!(du,u,X,p,t)\n    C, states = NN(u,p.NN, NNstates) # NNstates are\n    du[1] = p.r*u[1] - C[1] + p.beta[1] * X[1]\n    du[2] = p.theta*C[1] -p.m*u[2] + p.beta[2] * X[1]\nend\n\ninit_parameters = (NN = NNparameters, r = 1.0, m = 0.5, theta = 0.5, beta = [0,0])\n\n\nmodel = CustomDerivatives(training_data,X,derivs!;init_parameters;proc_weight=2.0,obs_weight=0.5,reg_weight=10^-4)\nnothing","category":"page"},{"location":"Models/#Adding-prior-information","page":"Model Constructors","title":"Adding prior information","text":"","category":"section"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"Users can add priors and custom neural network regularization functions by passing a function to the model constructor that takes the parameters as an argument and returns the loss associated with those parameter values. Please note that the loss functions defined by UniversalDiffEq.jl use the mean squared errors of the model rather than a likelihood function, so priors over the model parameters will not have the usual Bayesian interpretation.   ","category":"page"},{"location":"Models/","page":"Model Constructors","title":"Model Constructors","text":"UniversalDiffEq.CustomDerivatives(data::DataFrame,derivs!::Function,initial_parameters,priors::Function;kwargs ... )\nUniversalDiffEq.CustomDifference(data::DataFrame,step,initial_parameters,priors::Function;kwargs ... )","category":"page"},{"location":"Models/#UniversalDiffEq.CustomDerivatives-Tuple{DataFrame, Function, Any, Function}-Models","page":"Model Constructors","title":"UniversalDiffEq.CustomDerivatives","text":"CustomDerivatives(data::DataFrame,derivs!::Function,initial_parameters,priors::Function;kwargs ... )\n\nWhen a function's priors is supplied its value will be added to the loss function as a penalty term for user specified parameters. It should take the a single NamedTuple p as an argument penalties for each paramter should be calculated by accessing p with the period operator.\n\nThe prior function can be used to nudge the fitted model toward prior expectations for a parameter value. For example, the following function increases the loss when a parameter p.r has a value other than 1.5, nad a second parameter p.beta is greater than zeros. \n\nfunction priors(p)\n    l = 0.01*(p.r - 1.5)^2\n    l += 0.01*(p.beta)^2\n    return l\nend \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"Models/#UniversalDiffEq.CustomDifference-Tuple{DataFrame, Any, Any, Function}-Models","page":"Model Constructors","title":"UniversalDiffEq.CustomDifference","text":"CustomDifference(data::DataFrame,step,initial_parameters,priors::Function;kwargs ... )\n\nWhen a function's priors is supplied its value will be added to the loss function as a penalty term for user specified paramters. It should take the a single NamedTuple p as an argument penalties for each parameter should be calcualted by accessing p with the period operator. \n\nfunction priors(p)\n    l = 0.01*(p.r - 1.5)^2\n    l += 0.01*(p.beta)^2\n    return l\nend \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"ModelTesting/#Test-models","page":"Test models","title":"Test models","text":"","category":"section"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"UniversalDiffEq.jl provides a number of functions to test the performance of NODE and UDE models on in sample data. These test validate the model fitting procedure. Functions to estiamte the model's performance on out of sample data are discussed in the section on cross validation.  ","category":"page"},{"location":"ModelTesting/#Evaluating-model-fits","page":"Test models","title":"Evaluating model fits","text":"","category":"section"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"There are two primary functions to evaluate model fits: plot_state_estimates and plot_predictions. The training procedure used by UniversalDiffEq.jl simutaniously smooths the training data and trains trains the paramters of the UDE model on the smoothed data set. The funciton plot_state_estimates compares the smoothed time series produced by the training procedure to the observations in the data set. The smoothed time series (grey line) needs to capture the main trends in trainig data (blue dots) for the model to accurately recover the dynamics in the data set. ","category":"page"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"UniversalDiffEq.plot_state_estimates(UDE::UDE)","category":"page"},{"location":"ModelTesting/#UniversalDiffEq.plot_state_estimates-Tuple{UDE}-ModelTesting","page":"Test models","title":"UniversalDiffEq.plot_state_estimates","text":"plot_state_estimates(UDE::UDE)\n\nPlots the values of the state variables estimated by the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"We can make this analysis a bit more rigorous by looking for correlations in the obervation errors using the observation_error_correlations function. This creates a lag plot for each pair of variables in the model and calcualtes the correlation coeficent. Large correlations in the observation erros suggest the UDe model may be missing predictable variaiton in the data set. ","category":"page"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"UniversalDiffEq.observation_error_correlations(UDE;fig_size = (600,500))","category":"page"},{"location":"ModelTesting/#UniversalDiffEq.observation_error_correlations-Tuple{Any}-ModelTesting","page":"Test models","title":"UniversalDiffEq.observation_error_correlations","text":"observation_error_correlations(UDE)\n\nThe first differnce plot of the observation errors psilon_t. This allows the user to check for autocorrelation in the observation errors.   \n\n\n\n\n\n","category":"method"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"The plot_predictions  functions compares the predictions of UDE model one step into the future to the estimated sequence of state variables. This function quantifies the in sample predictive accuracy of the model. ","category":"page"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"UniversalDiffEq.plot_predictions(UDE::UDE)","category":"page"},{"location":"ModelTesting/#UniversalDiffEq.plot_predictions-Tuple{UDE}-ModelTesting","page":"Test models","title":"UniversalDiffEq.plot_predictions","text":"plot_predictions(UDE::UDE)\n\nPlots the correspondence between the observed state transitions and the predictions from the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"There are also functions to compare the model predictions to out-of-sample data. The simplest is plot_forecast, which compares the observations in the test data set to a deterministic simulation from the data set, which starts at the first observation and runs to the end of the test data. ","category":"page"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"UniversalDiffEq.plot_forecast(UDE::UDE, test_data::DataFrame)","category":"page"},{"location":"ModelTesting/#UniversalDiffEq.plot_forecast-Tuple{UDE, DataFrame}-ModelTesting","page":"Test models","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::UDE, test_data::DataFrame)\n\nPlots the model's forecast over the range of the test data along with the value of the test data.\n\n\n\n\n\n","category":"method"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"It is also possible to test the performance of the models one time step into the future using the plot_predictions function. When a test data set is supplied to the plot_predictions function, it will run a series of forecasts starting at each point in the data set, predicting one time step into the future. The function returns a plot comparing the predicted and observed changes.","category":"page"},{"location":"ModelTesting/","page":"Test models","title":"Test models","text":"UniversalDiffEq.plot_predictions(UDE::UDE, test_data::DataFrame)","category":"page"},{"location":"ModelTesting/#UniversalDiffEq.plot_predictions-Tuple{UDE, DataFrame}-ModelTesting","page":"Test models","title":"UniversalDiffEq.plot_predictions","text":"plot_predictions(UDE::UDE, test_data::DataFrame)\n\nPlots the correspondence between the observed state transitions in test data and the predictions from the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"ODEAnalysis/#Analyzing-fitted-models","page":"Analyzing fitted models","title":"Analyzing fitted models","text":"","category":"section"},{"location":"ODEAnalysis/","page":"Analyzing fitted models","title":"Analyzing fitted models","text":"UniversalDiffEq.equilibrium_and_stability(UDE,lower,upper;t=0,Ntrials=100,tol=10^-3)\nUniversalDiffEq.equilibrium_and_stability(UDE,X,lower,upper;t=0,Ntrials=100,tol=10^-3)\nUniversalDiffEq.equilibrium_and_stability(UDE::MultiUDE,site,X,lower,upper;t=0,Ntrials=100,tol=10^-3)","category":"page"},{"location":"ODEAnalysis/#UniversalDiffEq.equilibrium_and_stability-Tuple{Any, Any, Any}-ODEAnalysis","page":"Analyzing fitted models","title":"UniversalDiffEq.equilibrium_and_stability","text":"equilibrium_and_stability(UDE,lower,upper;t=0,Ntrials=100,tol=10^-3)\n\nAttempts to find all the equilibirum points for the UDE model between the upper and lower bound and return the real component of the leading eigen value to analyze stability. \n\n...\n\nkwargs\n\nt = 0: The point in time where the UDE model is evaluated, only relevant for time aware UDEs.\nNtrials = 100: the number of initializations of the root finding algorithm. \ntol = 10^-3: The threshold euclidean distance between point beyond which a new equilbirum is sufficently different to be retained. \n\n...\n\n\n\n\n\n","category":"method"},{"location":"ODEAnalysis/#UniversalDiffEq.equilibrium_and_stability-NTuple{4, Any}-ODEAnalysis","page":"Analyzing fitted models","title":"UniversalDiffEq.equilibrium_and_stability","text":"equilibrium_and_stability(UDE,X,lower,upper;t=0,Ntrials=100,tol=10^-3)\n\nAttempts to find all the equilibirum points for the UDE model between the upper and lower bound and return the real component of the leading eigen value to analyze stability. \n\n...\n\nkwargs\n\nt = 0: The point in time where the UDE model is evaluated, only relevant for time aware UDEs.\nNtrials = 100: the number of initializations of the root finding algorithm. \ntol = 10^-3: The threshold euclidean distance between point beyond which a new equilbirum is sufficently different to be retained. \n\n...\n\n\n\n\n\n","category":"method"},{"location":"ODEAnalysis/#UniversalDiffEq.equilibrium_and_stability-Tuple{MultiUDE, Any, Any, Any, Any}-ODEAnalysis","page":"Analyzing fitted models","title":"UniversalDiffEq.equilibrium_and_stability","text":"equilibrium_and_stability(UDE::MultiUDE,site,X,lower,upper;t=0,Ntrials=100,tol=10^-3)\n\nAttempts to find all the equilibirum points for the UDE model between the upper and lower bound and return the real component of the leading eigen value to analyze stability. \n\n...\n\nkwargs\n\nt = 0: The point in time where the UDE model is evaluated, only relevant for time aware UDEs.\nNtrials = 100: the number of initializations of the root finding algorithm. \ntol = 10^-3: The threshold euclidean distance between point beyond which a new equilbirum is sufficently different to be retained. \n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#API","page":"API","title":"API","text":"","category":"section"},{"location":"API/","page":"API","title":"API","text":"Modules = [UniversalDiffEq]","category":"page"},{"location":"API/#UniversalDiffEq.BayesianUDE","page":"API","title":"UniversalDiffEq.BayesianUDE","text":"BayesianUDE\n\nBasic data structure used to the model structure, parameters and data for Bayesian UDE and NODE models.  ...\n\nElements\n\ntimes: a vector of times for each observation\ndata: a matrix of observaitons at each time point\nX: a DataFrame with any covariates used by the model\ndata_frame: a DataFrame with columns for the time of each observation and values of the state variables\nparameters: a ComponentArray that stores model parameters\nloss_function: the loss function used to fit the model\nprocess_model: a Julia mutable struct used to define model predictions \nprocess_loss: a Julia mutable struct used to measure the performance of model predictions\nobservation_model: a Julia mutable struct used to predict observaitons given state variable estimates\nobservaiton_loss: a Julia mutable struct used to measure the performance of the observation model\nprocess_regularization: a Julia mutable struct used to store data needed for process model regularization\nobservation_regularization: a Julia mutable struct used to store data needed for observation model regularization\nconstructor: A function that initializes a UDE model with identical structure. \n\n...\n\n\n\n\n\n","category":"type"},{"location":"API/#UniversalDiffEq.LossFunction","page":"API","title":"UniversalDiffEq.LossFunction","text":"LossFunction\n\nA Julia mutable struct that stores the loss function and parameters. ...\n\nElements\n\nparameters: ComponentArray\nloss: Function \n\n...\n\n\n\n\n\n","category":"type"},{"location":"API/#UniversalDiffEq.MultiProcessModel","page":"API","title":"UniversalDiffEq.MultiProcessModel","text":"MultiProcessModel\n\nA Julia mutable struct that stores the functions and parameters for the process model.  ...\n\nElements\n\nparameters: ComponentArray\npredict: Function that predicts one time step ahead\nforecast: Function that is a modified version of predict to improve performace when extrapolating\ncovariates: Function that returns the values of the covariates at each point in time\nright_hand_side: Function that returns the right-hand side of a differential equation (i.e., the relationships between state variables and parameters)\n\n...\n\n\n\n\n\n","category":"type"},{"location":"API/#UniversalDiffEq.ProcessModel","page":"API","title":"UniversalDiffEq.ProcessModel","text":"ProcessModel\n\nA Julia mutable struct that stores the functions and parameters for the process model.  ...\n\nElements\n\nparameters: ComponentArray\npredict: Function the predict one time step ahead\nforecast: Function, a modified version of predict to improve performance when extrapolating\ncovariates: Function that returns the value of the covariates at each point in time. \n\n...\n\n\n\n\n\n","category":"type"},{"location":"API/#UniversalDiffEq.Regularization","page":"API","title":"UniversalDiffEq.Regularization","text":"Regularization\n\nA Julia mutable struct that stores the loss function and parameters. ...\n\nElements\n\nreg_parameters: ComponentArray\nloss: Function \n\n...\n\n\n\n\n\n","category":"type"},{"location":"API/#UniversalDiffEq.UDE","page":"API","title":"UniversalDiffEq.UDE","text":"UDE\n\nBasic data structure used to the model structure, parameters and data for UDE and NODE models.  ...\n\nElements\n\ntimes: a vector of times for each observation\ndata: a matrix of observaitons at each time point\nX: a DataFrame with any covariates used by the model\ndata_frame: a DataFrame with columns for the time of each observation and values of the state variables\nparameters: a ComponentArray that stores model parameters\nloss_function: the loss function used to fit the model\nprocess_model: a Julia mutable struct used to define model predictions \nprocess_loss: a Julia mutable struct used to measure the performance of model predictions\nobservation_model: a Julia mutable struct used to predict observaitons given state variable estimates\nobservaiton_loss: a Julia mutable struct used to measure the performance of the observation model\nprocess_regularization: a Julia mutable struct used to store data needed for process model regularization\nobservation_regularization: a Julia mutable struct used to store data needed for observation model regularization\nconstructor: A function that initializes a UDE model with identical structure.\ntimecolumnname: A string with the name of the column used for \nweights \nvariablecolumnname \nvaluecolumnname\n\n...\n\n\n\n\n\n","category":"type"},{"location":"API/#UniversalDiffEq.BFGS!-Tuple{Any}","page":"API","title":"UniversalDiffEq.BFGS!","text":" BFGS!(UDE, kwargs ...)\n\nminimizes the loss function of the UDE model using the BFGS algorithm is the inital step norm equal to initial_step_norm. The funciton will print the value fo the loss function after each iteration when verbose is true.  \n\nkwargs\n\ninitial_step_norm: Initial step norm for BFGS algorithm. Default is 0.01.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.BayesianCustomDerivatives-Tuple{DataFrame, Any, Function, Any}","page":"API","title":"UniversalDiffEq.BayesianCustomDerivatives","text":"BayesianCustomDerivatives(data::DataFrame,X,derivs!::Function,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame. \n\nWhen X is provided the derivs function must have the form derivs!(du,u,x,p,t) where x is a vector with the value of the covariates at time t. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.BayesianCustomDerivatives-Tuple{DataFrame, Function, Any}","page":"API","title":"UniversalDiffEq.BayesianCustomDerivatives","text":"BayesianCustomDerivatives(data::DataFrame,derivs!::Function,initial_parameters;kwargs ... )\n\nConstructs a Bayesian UDE model for the data set data  based on user defined derivatives derivs. An initial guess of model parameters are supplied with the initial_parameters argument. \n\n...\n\nArguments\n\ndata: a DataFrame object with the time of observations in a column labeled t and the remaining columns the value of the state variables at each time point. \nderivs: a Function of the form derivs!(du,u,p,t) where u is the value of the state variables, p are the model parameters, t is time, and du is updated with the value of the derivatives\ninit_parameters: A NamedTuple with the model parameters. Neural network parameters must be listed under the key NN.\n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.BayesianNODE-Tuple{Any, Any}","page":"API","title":"UniversalDiffEq.BayesianNODE","text":"BayesianNODE(data,X;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for values of time not included in the data frame. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.BayesianNODE-Tuple{Any}","page":"API","title":"UniversalDiffEq.BayesianNODE","text":"BayesianNODE(data;kwargs ... )\n\nConstructs a Bayesian continuous time model for the data set data using a single layer neural network to represent the systems dynamics. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.CustomDerivatives-Tuple{Any, Any, Any}","page":"API","title":"UniversalDiffEq.CustomDerivatives","text":"CustomDerivatives(data,derivs!,initial_parameters;kwargs ... )\n\nConstructs a UDE model for the data set data  based on user defined derivatives derivs. An initial guess of model parameters are supplied with the initial_parameters argument. \n\n...\n\nArguments\n\ndata: a DataFrame object with the time of observations in a column labeled t and the remaining columns the value of the state variables at each time point. \nderivs: a Function of the form derivs!(du,u,p,t) where u is the value of the state variables, p are the model parameters, t is time, and du is updated with the value of the derivatives\ninit_parameters: A NamedTuple with the model parameters. Neural network parameters must be listed under the key NN.\n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.CustomDerivatives-Tuple{DataFrame, DataFrame, Function, Any}","page":"API","title":"UniversalDiffEq.CustomDerivatives","text":"CustomDerivatives(data::DataFrame,X::DataFrame,derivs!::Function,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame. \n\nWhen X is provided the derivs function must have the form derivs!(du,u,x,p,t) where x is a vector with the value of the covariates at time t. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.CustomDerivatives-Tuple{DataFrame, Function, Any, Function}","page":"API","title":"UniversalDiffEq.CustomDerivatives","text":"CustomDerivatives(data::DataFrame,derivs!::Function,initial_parameters,priors::Function;kwargs ... )\n\nWhen a function's priors is supplied its value will be added to the loss function as a penalty term for user specified parameters. It should take the a single NamedTuple p as an argument penalties for each paramter should be calculated by accessing p with the period operator.\n\nThe prior function can be used to nudge the fitted model toward prior expectations for a parameter value. For example, the following function increases the loss when a parameter p.r has a value other than 1.5, nad a second parameter p.beta is greater than zeros. \n\nfunction priors(p)\n    l = 0.01*(p.r - 1.5)^2\n    l += 0.01*(p.beta)^2\n    return l\nend \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.CustomDifference-Tuple{Any, Any, Any}","page":"API","title":"UniversalDiffEq.CustomDifference","text":"CustomDifference(data,step,initial_parameters;kwrags...)\n\nConstructs a UDE model for the data set data based on user defined difference equation step. An initial guess of model parameters are supplied with the initial_parameters argument. ...\n\nArguments\n\ndata: a DataFrame object with the time of observations in a column labeled t and the remaining columns the value of the state variables at each time point. \nstep: a Function of the form step(u,t,p) where u is the value of the state variables, p are the model parameters.\ninit_parameters: A NamedTuple with the model parameters. Neural network parameters must be listed under the key NN.\n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.CustomDifference-Tuple{DataFrame, Any, Any, Any}","page":"API","title":"UniversalDiffEq.CustomDifference","text":"CustomDifference(data::DataFrame,X,step,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame. \n\nWhen X is provided the step function must have the form step(u,x,t,p) where x is a vector with the value of the covariates at time t. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.CustomDifference-Tuple{DataFrame, Any, Any, Function}","page":"API","title":"UniversalDiffEq.CustomDifference","text":"CustomDifference(data::DataFrame,step,initial_parameters,priors::Function;kwargs ... )\n\nWhen a function's priors is supplied its value will be added to the loss function as a penalty term for user specified paramters. It should take the a single NamedTuple p as an argument penalties for each parameter should be calcualted by accessing p with the period operator. \n\nfunction priors(p)\n    l = 0.01*(p.r - 1.5)^2\n    l += 0.01*(p.beta)^2\n    return l\nend \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.EasyNODE-Tuple{Any, Any}","page":"API","title":"UniversalDiffEq.EasyNODE","text":"EasyNODE(data,X;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for values of time not included in the data frame. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.EasyNODE-Tuple{Any}","page":"API","title":"UniversalDiffEq.EasyNODE","text":"EasyNODE(data;kwargs ... )\n\nConstructs a pretrained continuous time model for the data set data using a single layer neural network to represent the systems dynamics. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.EasyUDE-Tuple{Any, Any, Any}","page":"API","title":"UniversalDiffEq.EasyUDE","text":"EasyUDE(data,derivs!,initial_parameters;kwargs ... )\n\nConstructs a pretrained UDE model for the data set data  based on user defined derivatives derivs. An initial guess of model parameters are supplied with the initial_parameters argument. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.EasyUDE-Tuple{DataFrame, Any, Function, Any}","page":"API","title":"UniversalDiffEq.EasyUDE","text":"EasyUDE(data::DataFrame,X,derivs!::Function,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame.  When X is provided the derivs function must have the form derivs!(du,u,x,p,t) where x is a vector with the value of the covariates at time t. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.LorenzLotkaVolterra-Tuple{}","page":"API","title":"UniversalDiffEq.LorenzLotkaVolterra","text":"LorenzLotkaVolterra(;kwargs)\n\nCreate a sample dataset using the Lorenz Lotka-Volterra model as its process model:\n\n```math\n\frac{dx}{dt} = rx(1-\frac{x}{K}) - \u0007lpha xy + gz\\\n\frac{dy}{dt} = \theta\u0007lpha xy - my\\\n\frac{dz}{dt} = l(w-z)\\\n\frac{dw}{dt} = z(\rho-s) 0 w\\\n\frac{ds}{dt} = zw-\beta s\n```\n\nand an observation error following a normal distribution with mean 0 and standard deviation _{obs}.\n\n# kwargs\n- `plot`: Does the function return a plot? Default is `true`.\n- `seed`: Seed for observation error to create repeatable examples. Default is `123`.\n- `datasize`: Number of time steps generated. Default is `60`.\n- `T`: Maximum timespan. Default is `3.0`.\n- `sigma`: Standard deviation of observation error. Default is `0.075`.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.LotkaVolterra-Tuple{}","page":"API","title":"UniversalDiffEq.LotkaVolterra","text":"LotkaVolterra(;kwargs)\n\nCreate a sample dataset using the Lotka-Volterra predator-prey model as its process model:\n\n```math\n\frac{dN}{dt} = rN - \u0007lpha NP \\\n\frac{dP}{dt} = \theta\u0007lpha NP - mP\n```\n\nand an observation error following a normal distribution with mean 0 and standard deviation .\n\n# kwargs\n- `plot`: Does the function return a plot? Default is `true`.\n- `seed`: Seed for observation error to create repeatable examples. Default is `123`.\n- `datasize`: Number of time steps generated. Default is `60`.\n- `T`: Maximum timespan. Default is `3.0`.\n- `sigma`: Standard deviation of observation error. Default is `0.075`.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.MultiCustomDerivatives-Tuple{Any, Any, Any}","page":"API","title":"UniversalDiffEq.MultiCustomDerivatives","text":"MultiCustomDerivatives(data,derivs!,initial_parameters;kwargs...)\n\nBuilds a UDE model that can be trianed on multiple time series simultaniously. The user defined derivatives functions must allow for an extra argument i that indexes over the time seris in the data set (e.g. derivs!(du,u,i,)). data is a DataFrame object with time arguments placed in a column labeled t and a second column with a unique index for each time series. The remaining columns have observations of the state variables at each point in time and for each time series.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.MultiNODE-Tuple{Any, Any}","page":"API","title":"UniversalDiffEq.MultiNODE","text":"MultiNODE(data,X;kwargs...)\n\nWhen a dataframe X is supplied, the model will run with covariates. The argument X should have a column for time, a column for series index, a column for covariate names, and a column for the covariate values at each time step. The values in X will be interpolated with a linear spline for values of time not included in the dataframe. \n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.MultiNODE-Tuple{Any}","page":"API","title":"UniversalDiffEq.MultiNODE","text":"MultiNODE(data;kwargs...)\n\nBuilds a NODE model to fit to the data with multiple time series. data is a DataFrame object with time arguments placed in a column labeled t and a second column with a unique index for each time series. The remaining columns have observations of the state variables at each point in time and for each time series.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.NNDE-Tuple{Any}","page":"API","title":"UniversalDiffEq.NNDE","text":"NNDE(data;kwargs ...)\n\nConstructs a nonparametric discrete time model for the data set data using a single layer neural network to represent the systems dynamics. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".\nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.NODE-Tuple{Any, Any}","page":"API","title":"UniversalDiffEq.NODE","text":"NODE(data,X;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for values of time not included in the data frame. \n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.NODE-Tuple{Any}","page":"API","title":"UniversalDiffEq.NODE","text":"NODE(data;kwargs ... )\n\nConstructs a nonparametric continuous time model for the data set data using a single layer neural network to represent the systems dynamics. \n\n# kwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".    \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.NUTS!-Tuple{BayesianUDE}","page":"API","title":"UniversalDiffEq.NUTS!","text":" NUTS!(UDE, kwargs ...)\n\nperforms Bayesian estimation on the parameters of an UDE using the NUTS sampling algorithm.\n\nkwargs\n\ndelta: Step size used in NUTS adaptor. Default is 0.45.\nsamples: Number of parameters sampled. Default is 500.\nburnin: Number of samples used as burnin of Bayesian algorithm. Default is samples/10.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.SGLD!-Tuple{BayesianUDE}","page":"API","title":"UniversalDiffEq.SGLD!","text":" SGLD!(UDE, kwargs ...)\n\nPerforms Bayesian estimation on the parameters of an UDE using the SGLD sampling algorithm. At each step t, the stochastic update is provided by a random variable  with mean 0 and variance:\n\nmath a(b + t-1)^\n\nkwargs\n\na: Default is 10.0.\nb: Default is 1000.\n: Default is 0.9.\nsamples: Number of parameters sampled. Default is 500.\nburnin: Number of samples used as burnin of Bayesian algorithm. Default is samples/10.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.bifructaion_data-Tuple{MultiUDE}","page":"API","title":"UniversalDiffEq.bifructaion_data","text":"bifructaion_data(model::MultiUDE;N=25)\n\nCalcualtes the equilibrium values of the state variabels y_t as a function of the covariates X_t and return the value in a data frame. The funciton calcualtes the equilibrium values on a grid of N evenly spaced point for each covariate. The calcualtion are repeated for each time series i included in the training data set.  \n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.bifructaion_data-Tuple{UDE}","page":"API","title":"UniversalDiffEq.bifructaion_data","text":"bifructaion_data(model::UDE;N=25)\n\nCalcualtes the equilibrium values of the state variabels y_t as a function of the covariates X_t and return the value in a data frame. The funciton calcualtes the equilibrium values on a grid of N evenly spaced point for each covariate. \n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.cross_validation_kfold-Tuple{UDE}","page":"API","title":"UniversalDiffEq.cross_validation_kfold","text":"crossvalidationkfold(model::UDE; kwagrs...)\n\nThis funciton approximates model performance on out of sample data by leaving blocks of consequtive observaitons out of the training data. The model is trained on the remiaining observations and the and the one step ahead prediction accuracy is calcualted on the testing data set. This procedure is repeated k times.   ...\n\nArguments\n\nk = 10 - the number of testing data sets BFGS = false - weather or not to train the models with the BFGS algorithm  stepsize = 0.05 - the step size for the first round of gradient descent optimization  maxiter = 500 - the number of iterations for the first round of gradinet descent  stepsize2 = 0.05 - the step size for the second round of gradient descent  maxiter2 = 500 - the number of iterations for the second round of gradient descent N = 1000 - the number of particle to use in the particle filter algorithm that estiamtes the states in the out of sample data  nugget = 10^-10 - a small number to added variance terms in the particle filter algorith to improve numerical stability ...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.equilibrium_and_stability-NTuple{4, Any}","page":"API","title":"UniversalDiffEq.equilibrium_and_stability","text":"equilibrium_and_stability(UDE,X,lower,upper;t=0,Ntrials=100,tol=10^-3)\n\nAttempts to find all the equilibirum points for the UDE model between the upper and lower bound and return the real component of the leading eigen value to analyze stability. \n\n...\n\nkwargs\n\nt = 0: The point in time where the UDE model is evaluated, only relevant for time aware UDEs.\nNtrials = 100: the number of initializations of the root finding algorithm. \ntol = 10^-3: The threshold euclidean distance between point beyond which a new equilbirum is sufficently different to be retained. \n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.equilibrium_and_stability-Tuple{Any, Any, Any}","page":"API","title":"UniversalDiffEq.equilibrium_and_stability","text":"equilibrium_and_stability(UDE,lower,upper;t=0,Ntrials=100,tol=10^-3)\n\nAttempts to find all the equilibirum points for the UDE model between the upper and lower bound and return the real component of the leading eigen value to analyze stability. \n\n...\n\nkwargs\n\nt = 0: The point in time where the UDE model is evaluated, only relevant for time aware UDEs.\nNtrials = 100: the number of initializations of the root finding algorithm. \ntol = 10^-3: The threshold euclidean distance between point beyond which a new equilbirum is sufficently different to be retained. \n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.equilibrium_and_stability-Tuple{MultiUDE, Any, Any, Any, Any}","page":"API","title":"UniversalDiffEq.equilibrium_and_stability","text":"equilibrium_and_stability(UDE::MultiUDE,site,X,lower,upper;t=0,Ntrials=100,tol=10^-3)\n\nAttempts to find all the equilibirum points for the UDE model between the upper and lower bound and return the real component of the leading eigen value to analyze stability. \n\n...\n\nkwargs\n\nt = 0: The point in time where the UDE model is evaluated, only relevant for time aware UDEs.\nNtrials = 100: the number of initializations of the root finding algorithm. \ntol = 10^-3: The threshold euclidean distance between point beyond which a new equilbirum is sufficently different to be retained. \n\n...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.forecast-Tuple{BayesianUDE, AbstractVector, AbstractVector}","page":"API","title":"UniversalDiffEq.forecast","text":"forecast(UDE::BayesianUDE, u0::AbstractVector{}, times::AbstractVector{}; summarize = true, ci = 95)\n\npredictions from the trained model UDE starting at u0 saving values at times at each individual sampled parameter. Assumes u0 is the value at time times[1]\n\nIf summarize is true, this function returns the median prediction as well as the ci% lower and upper confidence intervals. Othwerise, it returns all the individual predictions for each sampled parameter.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.forecast-Tuple{BayesianUDE, AbstractVector, Real, AbstractVector}","page":"API","title":"UniversalDiffEq.forecast","text":"forecast(UDE::BayesianUDE, u0::AbstractVector{}, t0::Real, times::AbstractVector{}; summarize = true, ci = 95)\n\npredictions from the trained model UDE starting at u0 saving values at times at each individual sampled parameter. Assumes u0 occurs at time t0 and times are all larger than t0.\n\nIf summarize is true, this function returns the median prediction as well as the ci% lower and upper confidence intervals. Othwerise, it returns all the individual predictions for each sampled parameter.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.forecast-Tuple{UDE, AbstractVector, AbstractVector}","page":"API","title":"UniversalDiffEq.forecast","text":"forecast(UDE::UDE, u0::AbstractVector{}, times::AbstractVector{})\n\nPredictions from the trained UDE model starting at u0 and saving values at times. Assumes u0 is the value at initial time times[1]\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.forecast-Tuple{UDE, AbstractVector, Real, AbstractVector}","page":"API","title":"UniversalDiffEq.forecast","text":"forecast(UDE::UDE, u0::AbstractVector{}, t0::Real, times::AbstractVector{})\n\npredictions from the trained model UDE starting at u0 saving values at times. Assumes u0 occurs at time t0 and times are all larger than t0.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.get_NN_parameters-Tuple{UDE}","page":"API","title":"UniversalDiffEq.get_NN_parameters","text":"get_NN_parameters(UDE::UDE)\n\nReturns the values of the weights and biases of the neural network.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.get_parameters-Tuple{UDE}","page":"API","title":"UniversalDiffEq.get_parameters","text":"get_parameters(UDE::UDE)\n\nReturns model parameters.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.get_right_hand_side-Tuple{UDE}","page":"API","title":"UniversalDiffEq.get_right_hand_side","text":"get_right_hand_side(UDE::UDE)\n\nReturns the right-hand side of the differential equation (or difference equation) used to build the process model.\n\nThe function will take the state vector u and time t if the model does not include covariates. If covariates are included, then the arguments are the state vector u , covariates vector x, and time t.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.gradient_descent!-Tuple{Any}","page":"API","title":"UniversalDiffEq.gradient_descent!","text":" gradient_descent!(UDE, kwargs ...)\n\nMinimizes the loss function of the UDE model with the gradient descent algorithm with a step size of step_size and a maximum number of iterations of maxiter. Prints the value of the loss function after each iteration when maxiter is true.   \n\nkwargs\n\nstep_size: Step size for ADAM optimizer. Default is 0.05.\nmaxiter: Maximum number of iterations in gradient descent algorithm. Default is 500.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.kfold_cv-Tuple{UDE}","page":"API","title":"UniversalDiffEq.kfold_cv","text":"kfold_cv(model::UDE; kwargs ...)\n\nRuns K fold leave future out cross validation and returns the mean squared forecasting error and a plot to visualize the model fits.\n\n...\n\nArguments\n\nmodel - a UDE model object k=10 - the number of testing and taining data sets to build leaveout=5 - the number of data points to leave out in each testingdata set BFGS = false - use the BFGS algorithm to train the model stepsize = 0.05 - step size for first run of the ADAM algorithm  maxiter = 500 - maximum iterations for first trial of ADAM step_size2 = 0.01 - step size for second iteration of ADAM, only used of BFGS is false maxiter2 = 500 - step size for second iteration of ADAM, only used of BFGS is false ...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.leave_future_out_cv-Tuple{UDE}","page":"API","title":"UniversalDiffEq.leave_future_out_cv","text":"leave_future_out_cv(model::UDE; kwargs ...)\n\nRuns K fold leave future out cross validation and returns the mean squared forecasting error and a plot to visualize the model fits.\n\n...\n\nArguments\n\nmodel - the UDE model to test forecastlength = 5 - The number of data points to forecast forecastnumber = 10 - The number of trainin gnad testing data sets to create spacing = 2 - The number of data points to skip between the end of each new triaining data set BFGS=false - use BFGS algorithm to train the model stepsize = 0.05 - step size for first run of the ADAM algorithm  maxiter = 500 - maximum iterations for first trial of ADAM stepsize2 = 0.01 - step size for second iteration of ADAM, only used of BFGS is false maxiter2 = 500 - step size for second iteration of ADAM, only used of BFGS is false ...\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.observation_error_correlations-Tuple{Any}","page":"API","title":"UniversalDiffEq.observation_error_correlations","text":"observation_error_correlations(UDE)\n\nThe first differnce plot of the observation errors psilon_t. This allows the user to check for autocorrelation in the observation errors.   \n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.phase_plane-Tuple{UDE, AbstractArray}","page":"API","title":"UniversalDiffEq.phase_plane","text":"phase_plane(UDE::UDE, u0s::AbstractArray; idx=[1,2],T = 100)\n\nPlots the trajectory of state variables as forecasted by the model. Runs a forecast for each provided initial condition out to T timesteps. Change the state variables that are plotted by changing idx such that it equals the indexes of the desired state variables as they appear in the data.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.phase_plane-Tuple{UDE}","page":"API","title":"UniversalDiffEq.phase_plane","text":"phase_plane(UDE::UDE; idx=[1,2], u1s=-5:0.25:5, u2s=-5:0.25:5, u3s = 0, T = 100)\n\nPlots the trajectory of state variables as forecasted by the model. Runs a forecast for each permutation of u1 and u2 out to T timesteps. Change the state variables that are plotted by changing idx such that it equals the indexes of the desired state variables as they appear in the data.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.phase_plane_3d-Tuple{UDE}","page":"API","title":"UniversalDiffEq.phase_plane_3d","text":"phase_plane_3d(UDE::UDE; idx=[1,2,3], u1s=-5:0.25:5, u2s=-5:0.25:5, u3s=-5:0.25:5, T = 100)\n\nThe same as phase_plane(), but displays three dimensions/state variables instead of two.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_bifrucation_diagram-Tuple{MultiUDE, Any}","page":"API","title":"UniversalDiffEq.plot_bifrucation_diagram","text":"plot_bifrucation_diagram(model::UDE, xvariable; N = 25, color_variable= nothing, conditional_variable = nothing, size= (600, 400))\n\nThis function returns a plot of the equilibrium values of the state varaibles y_t as a funciton of the covariates X_t. The arguemnt xvariable determines the covariate plotted on the x-axis. Additional variables can be visualized in sperate panel by specifying the conditional_variable key word argument or visualized by the color scheme using the color_variable argument. \n\nThe time sereis are treated as an additional covariate that can be visualized by setting the color_variable or conditional_variable equal to \"series\" or the series column name in the training data. \n\nThe key word arguent size controls the dimensions of the final plot. \n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_bifrucation_diagram-Tuple{UDE, Any}","page":"API","title":"UniversalDiffEq.plot_bifrucation_diagram","text":"plot_bifrucation_diagram(model::UDE, xvariable; N = 25, color_variable= nothing, conditional_variable = nothing, size= (600, 400))\n\nThis function returns a plot of the equilibrium values of the state varaibles y_t as a funciton of the covariates X_t. The arguemnt xvariable determines the covariate plotted on the x-axis. Additional variables can be visualized in sperate panel by specifying the conditional_variable key word argument or visualized by the color scheme using the color_variable argument. \n\nThe key word arguent size controls the dimensions of the final plot. \n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_forecast-Tuple{BayesianUDE, DataFrame}","page":"API","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::BayesianUDE, test_data::DataFrame)\n\nPlots the model's forecast over the range of the test_data along with the value of the test data including the median prediction as well as the ci% lower and upper confidence intervals.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_forecast-Tuple{BayesianUDE, Int64}","page":"API","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::BayesianUDE, T::Int)\n\nPlots the models forecast up to T time steps into the future from the last observation including the median prediction as well as the ci% lower and upper confidence intervals.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_forecast-Tuple{UDE, DataFrame}","page":"API","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::UDE, test_data::DataFrame)\n\nPlots the model's forecast over the range of the test data along with the value of the test data.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_forecast-Tuple{UDE, Int64}","page":"API","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::UDE, T::Int)\n\nPlots the model's forecast up to T time steps into the future from the last observation.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_predictions-Tuple{BayesianUDE}","page":"API","title":"UniversalDiffEq.plot_predictions","text":"plot_predictions(UDE::BayesianUDE;ci=95)\n\nPlots the correspondence between the observed state transitons and the predicitons for the model UDE with a confidence interval ci.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_predictions-Tuple{UDE, DataFrame}","page":"API","title":"UniversalDiffEq.plot_predictions","text":"plot_predictions(UDE::UDE, test_data::DataFrame)\n\nPlots the correspondence between the observed state transitions in test data and the predictions from the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_predictions-Tuple{UDE}","page":"API","title":"UniversalDiffEq.plot_predictions","text":"plot_predictions(UDE::UDE)\n\nPlots the correspondence between the observed state transitions and the predictions from the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.plot_state_estimates-Tuple{UDE}","page":"API","title":"UniversalDiffEq.plot_state_estimates","text":"plot_state_estimates(UDE::UDE)\n\nPlots the values of the state variables estimated by the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.predict-Tuple{BayesianUDE, DataFrame}","page":"API","title":"UniversalDiffEq.predict","text":"predict(UDE::BayesianUDE,test_data::DataFrame;summarize = true,ci = 95,df = true)\n\nUses the Bayesian UDE UDE to predict the state of the data test_data for each of the sampled parameters in training.\n\nIf summarize is true, this function returns the median prediction as well as the ci% lower and upper confidence intervals. Othwerise, it returns all the individual predictions for each sampled parameter.\n\nIf df is true, this function returns a DataFrame object. Otherwise, it returns an Array with the predictions.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.print_parameter_estimates-Tuple{UDE}","page":"API","title":"UniversalDiffEq.print_parameter_estimates","text":"print_parameter_estimates(UDE::UDE)\n\nPrints the values of the known dynamics parameters estimated by the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"API/#UniversalDiffEq.vectorfield_and_nullclines-Tuple{Any}","page":"API","title":"UniversalDiffEq.vectorfield_and_nullclines","text":"vectorfieldandnullclines(UDE; kwargs)\n\nCalculate the vector field and nullclines of the 2D UDE model and returns their plot.\n\nkwargs\n\n-t: Time step t at which the vector field and nullclines are calculated. Default is 0. -n: Number of elements per axes to evaluate vector field at. Default is 15. -lower: Lower limits of vector field and nullclines. Default is [0.0,0.0]. -upper: Upper limits of vector field and nullclines. Default is [1.0,1.0]. -arrowlength: Arrow size of vector field plot. Default is 2. -arrow_color: Arrow color of vector field plot. Default is grey. -xlabel: X-label of vector field plot. Default is u1. -ylabel: Y-label of vector field plot. Default is u2. -title: Plot title. Default is Vector field. -color_u1: Color of nullcline in x-axis. Default is \"red\". -color_u2: Color of nullcline in y-axis. Default is \"black\". -legend: Position of legends of nullcines in plot. Default is :outerright.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/#Bayesian-Models","page":"Bayesian Models","title":"Bayesian Models","text":"","category":"section"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"UniversalDiffEq.jl provides training algorithms for uncertainty quantification in NODEs and UDEs using Bayesian NODEs and UDEs. UniversalDiffEq.jl currently supports the classical No-U-Turn Sampling (NUTS) and the Stochastic Gradient Langevin Dynamics (SGLD) algorithms. These algorithms are available for the BayesianUDE constructor. This constructor can be created using the BayesianNODE and BayesianCustomDerivatives functions. These functions follow the same structure as their non-Bayesian versions NODE and CustomDerivatives.","category":"page"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"UniversalDiffEq.BayesianNODE(data;kwargs ... )\nUniversalDiffEq.BayesianNODE(data,X;kwargs ... )\nUniversalDiffEq.BayesianCustomDerivatives(data::DataFrame,derivs!::Function,initial_parameters;kwargs ... )\nUniversalDiffEq.BayesianCustomDerivatives(data::DataFrame,X,derivs!::Function,initial_parameters;kwargs ... )","category":"page"},{"location":"BayesianModels/#UniversalDiffEq.BayesianNODE-Tuple{Any}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.BayesianNODE","text":"BayesianNODE(data;kwargs ... )\n\nConstructs a Bayesian continuous time model for the data set data using a single layer neural network to represent the systems dynamics. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/#UniversalDiffEq.BayesianNODE-Tuple{Any, Any}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.BayesianNODE","text":"BayesianNODE(data,X;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for values of time not included in the data frame. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/#UniversalDiffEq.BayesianCustomDerivatives-Tuple{DataFrame, Function, Any}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.BayesianCustomDerivatives","text":"BayesianCustomDerivatives(data::DataFrame,derivs!::Function,initial_parameters;kwargs ... )\n\nConstructs a Bayesian UDE model for the data set data  based on user defined derivatives derivs. An initial guess of model parameters are supplied with the initial_parameters argument. \n\n...\n\nArguments\n\ndata: a DataFrame object with the time of observations in a column labeled t and the remaining columns the value of the state variables at each time point. \nderivs: a Function of the form derivs!(du,u,p,t) where u is the value of the state variables, p are the model parameters, t is time, and du is updated with the value of the derivatives\ninit_parameters: A NamedTuple with the model parameters. Neural network parameters must be listed under the key NN.\n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n...\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/#UniversalDiffEq.BayesianCustomDerivatives-Tuple{DataFrame, Any, Function, Any}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.BayesianCustomDerivatives","text":"BayesianCustomDerivatives(data::DataFrame,X,derivs!::Function,initial_parameters;kwargs ... )\n\nWhen a dataframe X is supplied the model will run with covariates. the argument X should have a column for time t with the value for time in the remaining columns. The values in X will be interpolated with a linear spline for value of time not included in the data frame. \n\nWhen X is provided the derivs function must have the form derivs!(du,u,x,p,t) where x is a vector with the value of the covariates at time t. \n\nkwargs\n\ntime_column_name: Name of column in data that corresponds to time. Default is \"time\".  \nvariable_column_name: Name of column in data that corresponds to the variables. Default is \"variable\".\nvalue_column_name: Name of column in data that corresponds to the covariates. Default is \"value\".  \nhidden_units: Number of neurons in hidden layer. Default is 10.\nseed: Fixed random seed for repeatable results. Default is 1.\nproc_weight: Weight of process error omega_{proc}. Default is 1.0.\nobs_weight: Weight of observation error omega_{obs}. Default is 1.0.\nreg_weight: Weight of regularization error omega_{reg}. Default is 10^-6.\nreg_type: Type of regularization, whether \"L1\" or \"L2\" regularization. Default is \"L2\".\nl: Extrapolation parameter for forecasting. Default is 0.25.\nextrap_rho: Extrapolation parameter for forecasting. Default is 0.0.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/#Training-of-Bayesian-UDEs","page":"Bayesian Models","title":"Training of Bayesian UDEs","text":"","category":"section"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"Instead of training Bayesian UDEs using the gradient_descent! and BFGS! functions, we use the algorithms for Bayesian optimization. We repeat the tutorial for regular UDEs but create a BayesianUDE using BayesianCustomDerivatives instead of CustomDerivatives.","category":"page"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"using UniversalDiffEq, DataFrames, Lux, Random\n\ndata, plt = LotkaVolterra()\ndims_in = 2\nhidden_units = 10\nnonlinearity = tanh\ndims_out = 1\nNN = Lux.Chain(Lux.Dense(dims_in,hidden_units,nonlinearity),\n        Lux.Dense(hidden_units,dims_out))\n\n# initialize the neural network states and parameters \nrng = Random.default_rng() \nNNparameters, states = Lux.setup(rng,NN) \n\nfunction lotka_volterra_derivs!(du,u,p,t)\n    C, states = NN(u,p.NN,states) \n    du[1] = p.r*u[1] - C[1]\n    du[2] = p.theta*C[1] -p.m*u[2]\nend\n\ninitial_parameters = (NN = NNparameters, r = 1.0, m = 0.5, theta = 0.5)\nmodel = BayesianCustomDerivatives(data,lotka_volterra_derivs!,initial_parameters)","category":"page"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"Training is then done using NUTS! or SGLD!:","category":"page"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"NUTS!(model,samples = 500)","category":"page"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"NUTS!(UDE::BayesianUDE;kwargs ...)\nSGLD!(UDE::BayesianUDE;kwargs ...)","category":"page"},{"location":"BayesianModels/#UniversalDiffEq.NUTS!-Tuple{BayesianUDE}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.NUTS!","text":" NUTS!(UDE, kwargs ...)\n\nperforms Bayesian estimation on the parameters of an UDE using the NUTS sampling algorithm.\n\nkwargs\n\ndelta: Step size used in NUTS adaptor. Default is 0.45.\nsamples: Number of parameters sampled. Default is 500.\nburnin: Number of samples used as burnin of Bayesian algorithm. Default is samples/10.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/#UniversalDiffEq.SGLD!-Tuple{BayesianUDE}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.SGLD!","text":" SGLD!(UDE, kwargs ...)\n\nPerforms Bayesian estimation on the parameters of an UDE using the SGLD sampling algorithm. At each step t, the stochastic update is provided by a random variable  with mean 0 and variance:\n\nmath a(b + t-1)^\n\nkwargs\n\na: Default is 10.0.\nb: Default is 1000.\n: Default is 0.9.\nsamples: Number of parameters sampled. Default is 500.\nburnin: Number of samples used as burnin of Bayesian algorithm. Default is samples/10.\nverbose: Should the training loss values be printed?. Default is false.\n\n\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"The other functions for model analysis have methods for the BayesianUDE constructor:","category":"page"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"predict(UDE::BayesianUDE,test_data::DataFrame;summarize = true,ci = 95,df = true)","category":"page"},{"location":"BayesianModels/#UniversalDiffEq.predict-Tuple{BayesianUDE, DataFrame}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.predict","text":"predict(UDE::BayesianUDE,test_data::DataFrame;summarize = true,ci = 95,df = true)\n\nUses the Bayesian UDE UDE to predict the state of the data test_data for each of the sampled parameters in training.\n\nIf summarize is true, this function returns the median prediction as well as the ci% lower and upper confidence intervals. Othwerise, it returns all the individual predictions for each sampled parameter.\n\nIf df is true, this function returns a DataFrame object. Otherwise, it returns an Array with the predictions.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"plot_predictions(UDE::BayesianUDE;ci=95)","category":"page"},{"location":"BayesianModels/#UniversalDiffEq.plot_predictions-Tuple{BayesianUDE}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.plot_predictions","text":"plot_predictions(UDE::BayesianUDE;ci=95)\n\nPlots the correspondence between the observed state transitons and the predicitons for the model UDE with a confidence interval ci.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"plot_forecast(UDE::BayesianUDE, T::Int;ci = 95)","category":"page"},{"location":"BayesianModels/#UniversalDiffEq.plot_forecast-Tuple{BayesianUDE, Int64}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::BayesianUDE, T::Int)\n\nPlots the models forecast up to T time steps into the future from the last observation including the median prediction as well as the ci% lower and upper confidence intervals.\n\n\n\n\n\n","category":"method"},{"location":"BayesianModels/","page":"Bayesian Models","title":"Bayesian Models","text":"plot_forecast(UDE::BayesianUDE, test_data::DataFrame;ci = 95)","category":"page"},{"location":"BayesianModels/#UniversalDiffEq.plot_forecast-Tuple{BayesianUDE, DataFrame}-BayesianModels","page":"Bayesian Models","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::BayesianUDE, test_data::DataFrame)\n\nPlots the model's forecast over the range of the test_data along with the value of the test data including the median prediction as well as the ci% lower and upper confidence intervals.\n\n\n\n\n\n","category":"method"},{"location":"examples/#Examples","page":"Examples","title":"Examples","text":"","category":"section"},{"location":"examples/#Using-time-dependent-NODEs-to-predict-regime-changes","page":"Examples","title":"Using time-dependent NODEs to predict regime changes","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"One interesting use of NODE and UDE models in ecology is detecting and predicting regime changes, sudden shifts in the structure and function of an ecosystem caused by a small change in conditions. Regime changes are caused by the interaction of non-linear feedback mechanisms, environmental variability, and long-term environmental change. NODE and UDE models built with UniversalDiffEq.jl can capture all three of these processes, opening up the possibility of detecting and predicting regime changes from data.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"In the following example, we build a NODE model for a two-species system that undergoes a regime change. The data are simulated from the Mumby et al. (2007) model of coral-algae competition with an added term for stochastic coral mortality events and a long-term increase in the coral mortality rate from increasing temperature. The increasing temperature eventually causes the system to shift from a coral-dominated to an algae-dominated state (Fig. 1). The data from the time of the regime change are used to fit the model.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: Figure 1: simulated regime change data )","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The model is a function of the area covered by coral p_C and algae p_A, an environmental covariate X that is related to coral mortality and time t to capture the effect of the slowly increasing coral mortality rate. The coral and macroalgae abundances are transformed to x_i = softmax^-1(p_i) using the inverse softmax transformation before fitting the model","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"   fracdx_Cdt = NN_1(x_Cx_AXt) \n   fracdx_Adt = NN_2(x_Cx_AXt) ","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"UniversalDiffEq.jl does not have built-in methods to construct time-dependent NODEs, but they can be built easily using the CustomDerivatives function. In this case, we initialize a neural network that takes four inputs (one each for coral cover, algae cover, the environmental covariate, and time) and two outputs using Lux.jl. The derivatives function derivs! divides time by 50 to match the scale of the other inputs; then concatenates the abundances of each species, the covariate X, and time into a vector; and finally evaluates the neural network. The UDE model is constructed using the CustomDerivatives function, passing both the species data in a data frame called data and the covariate in a data frame called X.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Lux, UniversalDiffEq\n# set neural network dimensions\ndims_in = 4\ndims_out = 2\nhidden = 10\n\n\n# Define neural network with Lux.jl\nNN = Lux.Chain(Lux.Dense(dims_in, hidden, tanh), Lux.Dense(hidden, dims_out))\nrng = Random.default_rng()\nNNparameters, NNstates = Lux.setup(rng,NN)\nparameters = (NN = NNparameters,)\n\n\n# Define derivatives (time dependent NODE)\nfunction derivs!(du,u,X,p,t)\n    vals = NN([u[1],u[2],X[1],t/50-1.0],p.NN,NNstates)[1]\n    du[1] = vals[1]\n    du[2] = vals[2]\n    return du\nend\n\nmodel = UniversalDiffEq.CustomDerivatives(data[1:80,:],X,derivs!,parameters;proc_weight=2.5,obs_weight=10.0,reg_weight=10^-2.5)\n\ngradient_descent!(model, verbose = true, maxiter = 500)\ngradient_descent!(model, verbose = true, maxiter = 500, step_size = 0.01)\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We can use the plot_state_estimates and plot_predictions functions to test the fit of the model to the training data.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"UniversalDiffEq.plot_state_estimates(model)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"UniversalDiffEq.plot_predictions(model)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Unsurprisingly, given that this is simulated data, our model was able to fit the training data very closely.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"Given that the model fits the data well, we can move on to our analysis. The goal of this model is to capture the effects of a slowly changing variable on the dynamics of the coral-algae system. In particular, we want to identify any potential regime changes, points in time where a small change in the environment leads to a large change in the state of the ecosystem. Often, regime changes are characterized by the appearance or disappearance of equilibrium points in a dynamical system. We can identify these events by tracking changes in the derivatives function of the NODE model over time. This function is the right-hand side of a system of ODEs and, therefore, can be analyzed for equilibrium points and their stability. Because the NODE model is time-dependent, new equilibria may appear or existing ones may change their stability creating a regime change.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"To identify regime changes, we can extract the right-hand side of the ODE from the fitted model using the get_right_hand_side function. In the following example, we use the derivatives function RHS to plot a vector field for the coral and macroalgae at four points in time.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using Plots\np1 = vectorfield_and_nullclines(model,[0.0];t = 0, n = 15, lower = [-2.0,-2.0], upper = [2.0,2.0])\np2 = vectorfield_and_nullclines(model,[0.0];t = 70, n = 15, lower = [-2.0,-2.0], upper = [2.0,2.0])\np3 = vectorfield_and_nullclines(model,[0.0];t = 100, n = 15, lower = [-2.0,-2.0], upper = [2.0,2.0])\np4 = vectorfield_and_nullclines(model,[0.0];t = 130, n = 15, lower = [-2.0,-2.0], upper = [2.0,2.0])\nplt = plot(p1,p2,p3,p4)\nsavefig(plt,\"../docs/src/figures/regiem_changes_vector plots.png\")\nplt","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"The vector plots show clear changes in the dynamics of the system over time that likely constitute a regime change from a coral-dominated state an algae-dominated state. For small values of time, the vector fields all point to the upper left, which is high coral abundance and low algae abundance. Over time, however, a second equilibrium appears in the lower right: low coral and high algae abundance. The final vector field, t = 130, predicts 50 years into the future after the end of the time series. This plot predicts that the basin of attraction around the algae-dominated state will continue to grow, which is consistent with the data, and shows a sudden switch from high coral to high algae abundance.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We can also illustrate the regime shift in the system by plotting the equilibrium coral and algae abundances for different values of time using the equilibrium_and_stability function. The following code block uses equilibrium_and_stability to calculate the equilibrium point of the model at each point in time and colors stable equilibrium points black and unstable equilibrium points white. This analysis shows the coral-dominated equilibrium bifurcating into two equilibrium points after time 120. Some additional equilibrium points are also identified over time.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"p1 = Plots.plot(ylims = (-2.5,2.0), ylabel = \"Coral\")\np2 = Plots.plot(ylims = (-2.5,2.0), xlabel = \"Time\", ylabel = \"Algae\")\nfor t in 1:2:180\n    print(t,\" \")\n    eqs,evals = equilibrium_and_stability(model,[0.0],[-2.0,-2.0],[2.0,2.0];t=t,Ntrials=50)\n\n    for i in eachindex(eqs)\n        col = \"white\"\n        if evals[i] < 0\n            col = \"black\"\n        end\n        Plots.scatter!(p1,[t],eqs[i][2:2],color=col, label = \"\")\n        Plots.scatter!(p2,[t],eqs[i][1:1],color=col, label = \"\")\n    end\nend\nplt=Plots.plot(p1,p2,layout = (2,1))\nsavefig(plt,\"../docs/src/figures/regiem_changes_bifrucation_plot.png\")\nplt","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/#Using-UDEs-to-learn-the-dynamics-of-coupled-human-natural-systems","page":"Examples","title":"Using UDEs to learn the dynamics of coupled human-natural systems","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"Natural resources like fisheries are examples of coupled human and natural systems; human activities influence the state of the natural system, and the environment influences human activities. One of the primary goals of coupled human-natural systems research is understanding how these cycles of mutual causation determine biological and social outcomes. We may also wish to understand how interventions from regulators modify interactions between people and their environment to identify if these interventions achieve their desired effects.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"In this example, we build a UDE model to describe how the interactions between a fishing fleet and the exploited population change before and after the government limits entry into the fishery and predict the counterfactual outcomes in the absence of regulation.","category":"page"},{"location":"examples/#Data:-US-West-Coast-Cow-Cod-Fishery","page":"Examples","title":"Data: US West Coast Cow Cod Fishery","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"For this example, we use data from groundfish fisheries on the West Coast of the United States. These fisheries were managed under an open-access framework until 1992 when entry into the fishery was restricted following large declines in catch and abundance. We gathered data on the stock biomass B (proxy for abundance) and harvest H from the RAM legacy database and coded the change in regulations using binary variable I_LE that switched from zero to one in 1992 when limited entry regulations began. The time series of these three variables are shown below.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"using CSV, Plots, DataFrames\ndata = CSV.read(\"CowCodFishery.csv\",DataFrame)\nplt = Plots.scatter(data.t,data.y, label = \"log Abundance\", xlabel = \"Time\", ylabel = \"value\", width = 2)\nPlots.scatter!(data.t,data.H, label = \"Harvest\", width = 2)\nPlots.scatter!(data.t,data.limited_entry, label = \"Limited entry\", width = 2)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/#Model","page":"Examples","title":"Model","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"We use a logistic growth model to describe the changes in the population biomass and model changes in harvest as a function of the stock, the current harvest, and regulations. The factors that drive changes in harvest may be complex and non-linear so we use a neural network to model the rate of change of harvest. Combining these assumptions yields a system of differential equations that we fit into the data using the UniversalDiffEq.jl package","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"fracdHdt = NN(HBI_LEwb)\n\nfracdBdt = rB(1-BK) - qH","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"where r is the growth rate of the population, K is the carrying capacity, q is a scaling factor to match the units of stock biomass and harvest, w is the set of neural network weights, and b is the set of neural network biases. We define the model using a neural network from Lux.jl and the CustomDerivatives function. We fit the model parameters using the gradient descent and BFGS algorithms.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"# set up neural network\nusing UniversalDiffEq, Lux, Random,\ndims_in = 3\nhidden = 10\nNN = Lux.Chain(Lux.Dense(dims_in,hidden,tanh),Lux.Dense(hidden,1))\nrng = Random.default_rng()\nNNparameters, NNstates = Lux.setup(rng,NN)\n\n# set initial parameters\ninit_parameters = (NN = NNparameters, q = 1.0, r = 0.5, K = 4.0)\n\n# Define model\nfunction derivs!(du,u,X,p,t)\n    du[1] = NN(vcat(u,X),p.NN,NNstates)[1][1] # harvest\n    du[2] = p.r*u[2]*(1-u[2]/p.K) - p.q*u[1] # logistic growth minus harvest x scaling coef\nend\n\n# organize data\nstate_variables = DataFrame(t = data.t, H = data.H, y = exp.(data.y))\ncovariates = DataFrame(t = data.t, X = data.limited_entry)\n\n# initialize model\nmodel = CustomDerivatives(state_variables,covariates,derivs!,init_parameters;proc_weight=2.0,obs_weight=0.5,reg_weight=10^-4.0)\n\n# fit the model\ngradient_descent!(model,verbose = true)\nBFGS!(model,verbos = true)\nnothing","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"We can evaluate the model fit using plot_state_estimates and plot_predictions functions to compare the estimated state variables to the data and the predicted changes in state to the observed changes between time steps. The fitted model performs well by visual inspection on both metrics.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"p1 = plot_state_estimates(model)\np2 = plot_predictions(model)\nplot(p1,p2, layout= (2,1))","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/#Results:","page":"Examples","title":"Results:","text":"","category":"section"},{"location":"examples/#Counterfactual-prediction","page":"Examples","title":"Counterfactual prediction","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"We use the model to predict the harvest level and abundance of the population under limited entry and open access after 1992 when regulations were imposed. Under limited entry, the model predictions closely match historical data, with harvest decreasing and abundance increasing. Under open access conditions, the model predicts the system will approach an equilibrium with much lower abundance than observed in the historical data with harvest remaining relatively constant after 1992.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"u1991 = reshape(model.data[:,model.times .== 1991],2)\ntimes_OA = collect(1940:1972) # 22 years under open access conditions\ntimes_LE = collect(1991:2020) # 22 years under regulation\nforecast_OA = UniversalDiffEq.forecast(model,u1991, times_OA)\nforecast_LE = UniversalDiffEq.forecast(model,u1991, times_LE)\nplt = Plots.scatter(state_variables.t, state_variables.H,c=1, label = \"Catch Historical\")\nPlots.scatter!(state_variables.t,log.(state_variables.y),c=2, label = \"Abundance Historical\")\nPlots.plot!(1991 .+ forecast_OA[:,1] .- forecast_OA[1,1], forecast_OA[:,2], width = 2,c=1, label = \"Catch Counter Factual\")\nPlots.plot!(1991 .+ forecast_OA[:,1].- forecast_OA[1,1],log.(forecast_OA[:,3]), width = 2,c=2, label = \"Abundance Counter Factual\",xlabel = \"Time\", ylabel = \"(log) Biomass\")\nPlots.plot!(forecast_LE[:,1], forecast_LE[:,2], width = 2,c=1, label = \"Forecast\", linestyle = :dash)\nPlots.plot!(forecast_LE[:,1],log.(forecast_LE[:,3]), width = 2,c=2, label = \"Forecast\", xlabel = \"Time\", ylabel = \"(log) Biomass\", linestyle = :dash)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"examples/#Dynamics-before-and-after-regulation","page":"Examples","title":"Dynamics before and after regulation","text":"","category":"section"},{"location":"examples/","page":"Examples","title":"Examples","text":"The limited entry regulations produced a qualitative change in the dynamics of the coupled human-natural system. Prior to regulations, our model predicts the system had oscillating dynamics around a stable equilibrium. These dynamics are characteristic of the bioeconomic cycles predicted by theoretical models of open-access fisheries. When regulated, the cycling dynamics disappear and the model predicts declining harvest and increasing biomass over most of the state space.","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"p1 = vectorfield_and_nullclines(model,0, upper = [0.3,4.0], arrow_color = \"blue\",legend = :none,title = \"Open Access\",xlabel = \"Harvest\", ylabel = \"Abundance\")\np2 = vectorfield_and_nullclines(model,1, upper = [0.3,4.0], arrow_color = \"blue\",legend = :topright,title = \"Limited Entry\",xlabel = \"Harvest\", ylabel = \"\")\nplt = plot(p1,p2)","category":"page"},{"location":"examples/","page":"Examples","title":"Examples","text":"(Image: )","category":"page"},{"location":"MultipleTimeSeries/#Fitting-a-model-to-multiple-time-series","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"","category":"section"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"UniversalDiffEq.jl provides a set of functions to fit models to multiple time series. The functions for this mirror the functions for fitting NODEs and UDEs to single time series with the prefix Multi. For example, to build a NODE model for multiple time series you would use the MultiNODE function. The functions for model fitting, testing, and visualization have the same names. The other important difference is the data format: a column with a unique index for each time series must be included. ","category":"page"},{"location":"MultipleTimeSeries/#Dataframe","page":"Fitting a model to multiple time series","title":"Dataframe","text":"","category":"section"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"t series x1 x2\n1 1 x_11t x_12t\n2 1 x_11t x_12t\n3 1 x_11t x_12t\n1 2 x_21t x_22t\n2 2 x_21t x_22t\n3 2 x_21t x_22t","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"UniversalDiffEq.MultiNODE(data;kwargs...)\nUniversalDiffEq.MultiNODE(data,X;kwargs...)","category":"page"},{"location":"MultipleTimeSeries/#UniversalDiffEq.MultiNODE-Tuple{Any}-MultipleTimeSeries","page":"Fitting a model to multiple time series","title":"UniversalDiffEq.MultiNODE","text":"MultiNODE(data;kwargs...)\n\nBuilds a NODE model to fit to the data with multiple time series. data is a DataFrame object with time arguments placed in a column labeled t and a second column with a unique index for each time series. The remaining columns have observations of the state variables at each point in time and for each time series.\n\n\n\n\n\n","category":"method"},{"location":"MultipleTimeSeries/#UniversalDiffEq.MultiNODE-Tuple{Any, Any}-MultipleTimeSeries","page":"Fitting a model to multiple time series","title":"UniversalDiffEq.MultiNODE","text":"MultiNODE(data,X;kwargs...)\n\nWhen a dataframe X is supplied, the model will run with covariates. The argument X should have a column for time, a column for series index, a column for covariate names, and a column for the covariate values at each time step. The values in X will be interpolated with a linear spline for values of time not included in the dataframe. \n\n\n\n\n\n","category":"method"},{"location":"MultipleTimeSeries/#Multiple-time-series-custom-models","page":"Fitting a model to multiple time series","title":"Multiple time series custom models","text":"","category":"section"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"Custom models can be trained on multiple time series using the MultiCustomDerivatives function. The user-defined function that builds these models requires an additional argument, i added as the third argument  (e.g., derivs!(du,u,i,X,p,t), derivs!(du,u,i,p,t)). The UniversalDiffEq.jl library will use this argument to pass a unique index for each time series. These indices can then be used to estimate different parameter values for each time series as illustrated in the following examples. ","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"UniversalDiffEq.MultiCustomDerivatives(data,derivs!,initial_parameters;kwargs...)","category":"page"},{"location":"MultipleTimeSeries/#UniversalDiffEq.MultiCustomDerivatives-Tuple{Any, Any, Any}-MultipleTimeSeries","page":"Fitting a model to multiple time series","title":"UniversalDiffEq.MultiCustomDerivatives","text":"MultiCustomDerivatives(data,derivs!,initial_parameters;kwargs...)\n\nBuilds a UDE model that can be trianed on multiple time series simultaniously. The user defined derivatives functions must allow for an extra argument i that indexes over the time seris in the data set (e.g. derivs!(du,u,i,)). data is a DataFrame object with time arguments placed in a column labeled t and a second column with a unique index for each time series. The remaining columns have observations of the state variables at each point in time and for each time series.\n\n\n\n\n\n","category":"method"},{"location":"MultipleTimeSeries/#Example-1:-estimating-unique-growth-rates-for-population-time-series","page":"Fitting a model to multiple time series","title":"Example 1: estimating unique growth rates for population time series","text":"","category":"section"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"To illustrate how unique parameters can be estimated for separate time series, we build a generalized logistic model that uses a neural network to describe the density dependence of the populations and estimates unique growth rates for each time series","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"fracdu_idt = r_i u_i NN(u_i)","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"To build this model, we use the argument i of the derive function to index it into a vector of growth rate parameters. Notice that we need to transform i to be an integer for the indexing operation by calling round(Int,i) and we initialize the growth rate parameter r ","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"# set up neural network\nusing Lux\ndims_in = 1\nhidden_units = 10\nnonlinearity = tanh\ndims_out = 1\nNN = Lux.Chain(Lux.Dense(dims_in,hidden_units,nonlinearity),Lux.Dense(hidden_units,dims_out))\n\n# initialize parameters\nusing Random\nrng = Random.default_rng()\nNNparameters, NNstates = Lux.setup(rng,NN)\n\nfunction derivs!(du,u,i,X,p,t)\n    index = round(Int,i)\n    du .= p.r[i].* u .* NN(u,p.NN, NNstates)[1] # NNstates are\n\nend\n\nm = 3 # number of time series\ninit_parameters = (NN = NNparameters, r = zeros(m), m = 0.5, theta = 0.5, beta = [0,0])\n\nmodel = MultiCustomDerivatives(training_data,derivs!;init_parameters;proc_weight=2.0,obs_weight=0.5,reg_weight=10^-4)\nnothing\n","category":"page"},{"location":"MultipleTimeSeries/#Example-2:-allowing-a-neural-network-to-vary-between-time-series","page":"Fitting a model to multiple time series","title":"Example 2: allowing a neural network to vary between time series","text":"","category":"section"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"In some cases, we may want to allow the neural networks we use to estimate unknown functions to vary between time series. This can be achieved by passing an indicator variable to the neural network that encodes the time series being fit using a one-hot encoding. This method allows the model to learn unique functions for each time series if appropriate, while also sharing information about the unknown function between time series. ","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"To illustrate this define a NODE model that takes the indicator variable as an additional argument. ","category":"page"},{"location":"MultipleTimeSeries/","page":"Fitting a model to multiple time series","title":"Fitting a model to multiple time series","text":"# set up neural network\nm = 10 # number of time seires\nusing Lux\ndims_in = 2+m #two inputs for the state variable plus m inputs for the one-hot encoding \nhidden_units = 10\nnonlinearity = tanh\ndims_out = 2\nNN = Lux.Chain(Lux.Dense(dims_in,hidden_units,nonlinearity),Lux.Dense(hidden_units,dims_out))\n\n# initialize parameters\nusing Random\nrng = Random.default_rng()\nNNparameters, NNstates = Lux.setup(rng,NN)\n\nfunction derivs!(du,u,i,X,p,t)\n    index = round(Int,i)\n    one_hot = zeros(m)\n    one_hot[index] = 1\n    du .=  NN(vcat(u,one_hot) ,p.NN, NNstates)[1] # NNstates are\nend\n\ninit_parameters = (NN = NNparameters, )\n\nmodel = MultiCustomDerivatives(training_data,derivs!;init_parameters;proc_weight=2.0,obs_weight=0.5,reg_weight=10^-4)\nnothing","category":"page"},{"location":"#UniversalDiffEq.jl","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"","category":"section"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"UniversalDiffEq.jl is a library for building state-space universal dynamic equations (SS-UDEs) and neural ordinary differential equations (NODEs). These modes use neural networks to learn unknown nonlinear relationships from time series data. The package provides model constructor functions to build discrete and continuous time models that combine known parametric functions with unknown functions represented by neural networks. UniversalkDiffEq.jl defines a set of training procedures that can simultaneously estimate the parameters of known functions and train a neural network to represent unknown functions. The models are trained using a state space modeling procedure, which makes them robust to unexplained variation in the systems dynamics and measurement errors. The package leverages the Julia scientific machine learning ecosystem (SciML) to build and train the models. ","category":"page"},{"location":"#Universal-dynamic-equations","page":"UniversalDiffEq.jl","title":"Universal dynamic equations","text":"","category":"section"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"Universal dynamic equations include two classes of models: universal differential equations and universal difference equations. Universal differential equations are continuous-time models that learn the right-hand side of a system of ordinary differential equations from time series data","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"fracdudt = f(u)","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"Universal difference equations are discrete-time models that learn the right-hand side of a system of difference equations","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"u_t+1 = u_t + f(u)","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"In the simplest case, a neural network NN represents the entire right-hand side of the model f(bfmathx) = NN(bfmathx). These models are sometimes called neural ordinary differntial equaitons (NODEs). However, in general, the right-hand side of the model can include both neural networks and parametric functions. For example, the classic Loka Volterra predator-prey model includes a growth term for the prey rN, a mortality rate for the predator mN, and a linear interaction term between the two species alpha NP. We can use universal differential equations to build a more flexible version of this model by replacing the linear interaction term with a neural network ","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"fracdNdt = rN - NN(NP) \nfracdPdt = theta NN(NP) - mP","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"We can train the neural network NN and estimate the biological parameters r, m, and theta from time series data using the training routines defined in UniversalDiffEq.jl.","category":"page"},{"location":"#How-UniversalDiffEq.jl-works","page":"UniversalDiffEq.jl","title":"How UniversalDiffEq.jl works","text":"","category":"section"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"UniversalDiffEq.jl builds and trains universal dynamic equations within a state-space modeling framework. State-space models describe noisy time series data by combining two models: (1) an observation model that describes the relationship between the data and the actual underlying state of the system and (2) a process model that describes the changes in the system's state over time. This model structure allows state-space models to account for uncertainty caused by noisy observations (observation error) and inherent randomness within the system's dynamics (process error).","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"State-space models simultaneously estimate the parameters of the process and observation models theta and the value of the state variables at each point in time hatu_t. These parameters are estimated by optimizing a loss function that combines two components: the observation loss and the process loss. The observation loss compares the state estimates to the data y_t using the observaiton model g(u_t)","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"L_obs = frac1T sum_i = 1^T (y_t - g(hatu_ttheta ))^2","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"The process loss compares predictions of the process model f(u_ttheta) to the estimated states variables at the next time point","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"L_proc = frac1T-1 sum_i = 2^Tfrac1Delta t(hatu_t - f(hatu_t-1theta ))^2","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"The process loss is weighted by the inverse of the time between data points Delta t. ","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"In addition to the process and observaiton loss additional terms can be added to the loss funciton to regularize the neural network parmaters and to incorperate prior informaiton about the parameters of parametric functions","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"L_reg = R(theta)","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"The UniversalDiffEq.jl package combines weighted sums of these three components to create the full loss function","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"L(hatutheta) = omega_obs L_obs + omega_proc L_proc + omega_reg L_reg","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"UniversalDiffEq.jl uses Optimizers.jl to find the state and parameter estimates that minimize the loss function. Currently, two optimization algorithms are available, the Adam gradient descent algorithm and the quasi-Newton algorithm BFGS.","category":"page"},{"location":"#Data-types","page":"UniversalDiffEq.jl","title":"Data types","text":"","category":"section"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"UniversalDiffEq.jl can train models on individual time series y_t or panel of mutliple time series y_it from systmes with similar dynamics. Seperate model constructors are provided for models trained on single and multiple time series. UniversalDiffEq.jl allows the models trained on multiple time series to include parameters that have differnt values for each time series in the training set. ","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"UniversalDiffEq.jl can accomidate irregualrly sampled data. Data for continuous time models can be sampled at any point in time, while discrete time models requre and integer valued time steps between observations. UniversalDiffEq.jl does not accomidate observaitons that are missing a sub-set of the state variables.","category":"page"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"Models built with UniversalDiffEq.jl can incorperate covariates X_t that influence the dynamics of the primary state variables. Discrete time models require the the observations of the covariates to match the time when the state variables are observed ","category":"page"},{"location":"#Package-Contents","page":"UniversalDiffEq.jl","title":"Package Contents","text":"","category":"section"},{"location":"","page":"UniversalDiffEq.jl","title":"UniversalDiffEq.jl","text":"Pages = [\"Models.md\",\"MultipleTimeSeries.md\", \"ModelTesting.md\", \"CrossValidation.md\", \"NutsAndBolts.md\",\"modelanalysis.md\",\"examples.md\",\"API.md\"]","category":"page"},{"location":"modelanalysis/#Model-analysis","page":"Model analysis","title":"Model analysis","text":"","category":"section"},{"location":"modelanalysis/","page":"Model analysis","title":"Model analysis","text":"UniversalDiffEq.jl provides several functions to analyze the characteristics of the fitted models. The most basic of these is the get_right_hand_side function. This function takes a UDE model as an argument and returns the right-hand side of the fitted differential or difference equation. This function can then be treated like any dynamic model and analyzed for equilibria, stability, tipping points, and other phenomena of interest.  ","category":"page"},{"location":"modelanalysis/","page":"Model analysis","title":"Model analysis","text":"UniversalDiffEq.get_right_hand_side(UDE::UDE)","category":"page"},{"location":"modelanalysis/#UniversalDiffEq.get_right_hand_side-Tuple{UDE}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.get_right_hand_side","text":"get_right_hand_side(UDE::UDE)\n\nReturns the right-hand side of the differential equation (or difference equation) used to build the process model.\n\nThe function will take the state vector u and time t if the model does not include covariates. If covariates are included, then the arguments are the state vector u , covariates vector x, and time t.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/","page":"Model analysis","title":"Model analysis","text":"The library also has functions to evaluate model predictions. The forecast function will run a simulation of the model starting at the initial point u0 and returning the value of the state variables at each point in the times vector.  ","category":"page"},{"location":"modelanalysis/","page":"Model analysis","title":"Model analysis","text":"The function phase_plane plots forecasted trajectories of state variables for a given number of timesteps T. All phase plane functions also work with the MultiUDE model type, and plot phase planes for each series in the data.","category":"page"},{"location":"modelanalysis/","page":"Model analysis","title":"Model analysis","text":"UniversalDiffEq.phase_plane(UDE::UDE; idx=[1,2], u1s=-5.0,0.25,5.0, u2s=-5:0.25:5,u3s = 0,T = 100)\nUniversalDiffEq.phase_plane(UDE::UDE, u0s::AbstractArray; idx=[1,2],T = 100)\nUniversalDiffEq.phase_plane_3d(UDE::UDE; idx=[1,2,3], u1s=-5.0,0.25,5.0, u2s=-5:0.25:5,u3s=-5:0.25:5,T = 100)","category":"page"},{"location":"modelanalysis/#UniversalDiffEq.phase_plane-Tuple{UDE}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.phase_plane","text":"phase_plane(UDE::UDE; idx=[1,2], u1s=-5:0.25:5, u2s=-5:0.25:5, u3s = 0, T = 100)\n\nPlots the trajectory of state variables as forecasted by the model. Runs a forecast for each permutation of u1 and u2 out to T timesteps. Change the state variables that are plotted by changing idx such that it equals the indexes of the desired state variables as they appear in the data.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/#UniversalDiffEq.phase_plane-Tuple{UDE, AbstractArray}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.phase_plane","text":"phase_plane(UDE::UDE, u0s::AbstractArray; idx=[1,2],T = 100)\n\nPlots the trajectory of state variables as forecasted by the model. Runs a forecast for each provided initial condition out to T timesteps. Change the state variables that are plotted by changing idx such that it equals the indexes of the desired state variables as they appear in the data.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/#UniversalDiffEq.phase_plane_3d-Tuple{UDE}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.phase_plane_3d","text":"phase_plane_3d(UDE::UDE; idx=[1,2,3], u1s=-5:0.25:5, u2s=-5:0.25:5, u3s=-5:0.25:5, T = 100)\n\nThe same as phase_plane(), but displays three dimensions/state variables instead of two.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/","page":"Model analysis","title":"Model analysis","text":"UniversalDiffEq.forecast(UDE::UDE, u0::AbstractVector, times::AbstractVector)\nUniversalDiffEq.print_parameter_estimates(UDE::UDE)\nUniversalDiffEq.plot_forecast(UDE::UDE, T::Int)\nUniversalDiffEq.get_NN_parameters(UDE::UDE)\nUniversalDiffEq.get_parameters(UDE::UDE)","category":"page"},{"location":"modelanalysis/#UniversalDiffEq.forecast-Tuple{UDE, AbstractVector, AbstractVector}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.forecast","text":"forecast(UDE::UDE, u0::AbstractVector{}, times::AbstractVector{})\n\nPredictions from the trained UDE model starting at u0 and saving values at times. Assumes u0 is the value at initial time times[1]\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/#UniversalDiffEq.print_parameter_estimates-Tuple{UDE}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.print_parameter_estimates","text":"print_parameter_estimates(UDE::UDE)\n\nPrints the values of the known dynamics parameters estimated by the UDE model.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/#UniversalDiffEq.plot_forecast-Tuple{UDE, Int64}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.plot_forecast","text":"plot_forecast(UDE::UDE, T::Int)\n\nPlots the model's forecast up to T time steps into the future from the last observation.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/#UniversalDiffEq.get_NN_parameters-Tuple{UDE}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.get_NN_parameters","text":"get_NN_parameters(UDE::UDE)\n\nReturns the values of the weights and biases of the neural network.\n\n\n\n\n\n","category":"method"},{"location":"modelanalysis/#UniversalDiffEq.get_parameters-Tuple{UDE}-modelanalysis","page":"Model analysis","title":"UniversalDiffEq.get_parameters","text":"get_parameters(UDE::UDE)\n\nReturns model parameters.\n\n\n\n\n\n","category":"method"}]
}
