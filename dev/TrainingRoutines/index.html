<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Training routines · UniversalDiffEq.jl</title><meta name="title" content="Training routines · UniversalDiffEq.jl"/><meta property="og:title" content="Training routines · UniversalDiffEq.jl"/><meta property="twitter:title" content="Training routines · UniversalDiffEq.jl"/><meta name="description" content="Documentation for UniversalDiffEq.jl."/><meta property="og:description" content="Documentation for UniversalDiffEq.jl."/><meta property="twitter:description" content="Documentation for UniversalDiffEq.jl."/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">UniversalDiffEq.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">UniversalDiffEq.jl</a></li><li><a class="tocitem" href="../Models/">Model Constructors</a></li><li class="is-active"><a class="tocitem" href>Training routines</a><ul class="internal"><li><a class="tocitem" href="#Gradient-matching-loss-function"><span>Gradient matching loss function</span></a></li><li><a class="tocitem" href="#State-space-loss-functions"><span>State-space loss functions</span></a></li><li><a class="tocitem" href="#Shooting-loss-function"><span>Shooting loss function</span></a></li><li><a class="tocitem" href="#Multiple-shooting-loss-function"><span>Multiple shooting loss function</span></a></li><li><a class="tocitem" href="#ADAM-optimizer"><span>ADAM optimizer</span></a></li><li><a class="tocitem" href="#BFGS-optimizer"><span>BFGS optimizer</span></a></li></ul></li><li><a class="tocitem" href="../ModelTesting/">Model performance</a></li><li><a class="tocitem" href="../CrossValidation/">Cross validation</a></li><li><a class="tocitem" href="../NutsAndBolts/">UDE model construction</a></li><li><a class="tocitem" href="../MultipleTimeSeries/">Fitting a model to multiple time series</a></li><li><a class="tocitem" href="../modelanalysis/">Model analysis</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li><a class="tocitem" href="../API/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Training routines</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Training routines</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/Jack-H-Buckner/UniversalDiffEq.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/Jack-H-Buckner/UniversalDiffEq.jl/blob/main/docs/src/TrainingRoutines.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Training-routines"><a class="docs-heading-anchor" href="#Training-routines">Training routines</a><a id="Training-routines-1"></a><a class="docs-heading-anchor-permalink" href="#Training-routines" title="Permalink"></a></h1><p>There are many differnt methods for training NODE and UDE models. These methods trade off between accuracy, stability, and computing time. Their performance may also be related to the characteristics of the training data. However, this is an active area of research where it is difficult to make definitive statements.</p><p>Currently, UniversalDiffEq.jl implements five loss functions and two different optimization algorithms that can be accessed through the <code>train!</code> function. The logic behind each method and the implementation details can be found below.</p><h2 id="Gradient-matching-loss-function"><a class="docs-heading-anchor" href="#Gradient-matching-loss-function">Gradient matching loss function</a><a id="Gradient-matching-loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-matching-loss-function" title="Permalink"></a></h2><h3 id="Method-description"><a class="docs-heading-anchor" href="#Method-description">Method description</a><a id="Method-description-1"></a><a class="docs-heading-anchor-permalink" href="#Method-description" title="Permalink"></a></h3><p>Gradient matching is the most computationally efficient training procedure implemented by UniversalDiffEq.jl. It works for continuous time models such as those implemented by <code>CustomDerivatives</code> or <code>NODE</code> model-building functions. This method was adapted from a tutorial in the DiffEqFlux.jl (documentation)[https://docs.sciml.ai/DiffEqFlux/stable/examples/collocation/] called smooth collocation for fast two-stage training.</p><p>Gradient matching trains the models using a two-step procedure. First, the algorithm fits a smoothing curve <span>$s_i(t)$</span> to each dimension <span>$i$</span> of the time series using a cubic spline implemented by the DataInterpolations.jl package. The model is trained by comparing the right-hand side <span>$f$</span> of the UDE model to the derivatives of the smoothing curve, evaluated at the time of each observation in the data set.</p><p class="math-container">\[   L(\theta) = \sum_i \sum_{\tau\in T} \left(\frac{ds_i}{dt} |_\tau - f_i(s(\tau)\right)^2 + \omega_R |\theta_{w}|_{L2}\]</p><p>The final term <span>$\omega_R |\theta_{w}|_{L2} $ applies $L2$</span> regualrization to the neural network weights <span>$\theta_{w}$</span>. The user can specify the weight <span>$\omega_R$</span> using the keyword argument <code>Regularization_weight</code> in the <code>train!</code> function.</p><p>The algorithm can be tuned for a specific data set using the <code>loss_options</code> keyword argument. This argument should be a NamedTyple with values <code>d</code> and <code>remove_ends</code>. The parameter <code>d</code> sets the number of degrees of freedom used by the curve-fitting model. The <code>remove_ends</code> option is an integer. This allows data points from the beginning and end of the data set to be excluded from the loss function. The default value is zero (no observations are excluded), but the smoothing curves might fit poorly near the beginning and end of some data sets. Setting <code>remove_ends &gt; 0</code> can help reduce the influence of these edge effects on the trained model.The smoothing curves are fit using the generalized cross-validation method in the (DataInterpolations.jl)[https://docs.sciml.ai/DataInterpolations/dev/methods/#Regularization-Smoothing] package. This method fits a continuous, differentiable curve to the data with a smoothing penalty term chosen to minimize the influence of observaiton errors.</p><p>The success of the training procedure can be evaluated using the <code>plot_state_estimates</code> and <code>plot_predictions</code> functions. The <code>plot_state_estimates</code> will plot the data using a scatter plot and overlay the smoothing curves with a line plot, allowing a visual inspection of the fits. The plot predictions function will show how well the trained UDE predicts the changes in the smoothing curves ,forecasting one step ahead. </p><h3 id="Implementation"><a class="docs-heading-anchor" href="#Implementation">Implementation</a><a id="Implementation-1"></a><a class="docs-heading-anchor-permalink" href="#Implementation" title="Permalink"></a></h3><p>The gradient matching loss function is implemented using the <code>train</code> function by setting the key work argument <code>loss_function=&quot;gradient matching</code>.  The behavior of the loss function can be modified by supplying a value for the <code>regularization_weight</code> weight by providing the degrees of freedom <code>d</code> and edge effects <code>remove_ends</code> using the <code>loss_options</code> argument. The block of Julia code below shows the default values for each argument.</p><pre><code class="language-julia hljs">train!(model;
       loss_function = &quot;gradient matching&quot;,
       regularization_weight = 0.0,
       loss_options = (d = 12, remove_ends = 0)
   )</code></pre><p>Note that if only one value is provided to <code>loss_options</code> it needs to be followed by a comma (e.g. <code>loss_options=(d = 12,)</code>)</p><h2 id="State-space-loss-functions"><a class="docs-heading-anchor" href="#State-space-loss-functions">State-space loss functions</a><a id="State-space-loss-functions-1"></a><a class="docs-heading-anchor-permalink" href="#State-space-loss-functions" title="Permalink"></a></h2><p>State-space loss functions assume the data <span>$y_t \in R^d$</span> can be described by a set of state variables <span>$u_t \in R^d$</span> and observation errors <span>$\epsilon_t \in R^d$</span>. The UDE model <span>$f(u,X(t),t|\theta)$</span> with parameters <span>$\theta$</span> and covariates <span>$X$</span> is used to learn the dynamics of the state variables <span>$u_t$</span>.  Combining these assumptions yields two equations that describe the observation set <span>$y_t$</span></p><p class="math-container">\[   y_t = u_t + \epsilon_t \\
   u_{t+1} = u_t + \int_{t}^{t+1} f(u,X(v),v|\theta) dv + \nu_t\]</p><p>Given these two equations, we can calculate the likelihood of the data <span>$y_t$</span> given the parameters of the UDE <span>$\theta$</span> in two ways, the conditional and marginal likelihood. The conditional likelihood is used in Bayesian settings and describes the likelihood of the data given the UDE parameters <span>$\theta$</span> and point estimates of the state variables <span>$\hat{u}_t$</span>. The marginal likelihood describes the likelihood of the observations <span>$y_t$</span> given the model parameters <span>$\theta$</span> while accounting for uncertianty in the estimates of the state variables <span>$u_t$</span>. The marginal likelihood is used in a frequenties setting and produces unbiased maximum likelihood estimates of the parameters <span>$\theta$</span>. In practice, both likelihood functions can be used to train the UDE models with good results. The conditional likelihood is more computationally efficient, while the marginal likelihood is more accurate in theory.</p><h3 id="Conditional-likelihood"><a class="docs-heading-anchor" href="#Conditional-likelihood">Conditional likelihood</a><a id="Conditional-likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Conditional-likelihood" title="Permalink"></a></h3><p>To start, we need to specify a family of distributions for the observaiton and process errors. Our implementation assumes these terms follow multivariate normal distributions with mean zero and covariance <span>$\Sigma_{proc}$</span> and <span>$\Sigma_{obs}$</span>. The covariance matrices must be supplied by the user for the conditional likelihood approach.</p><p>Given the distributional assumptio, the log-likelihood function has two components, a term corresponding to the observation errors and a term corresponding to the process errors. The observaiton error term comparte the differnce between the obervations <span>$y_t$</span> and estimated states <span>$\hat{u}_t$</span> weighted by the observaiton error matrix <span>$\Sigma_{obs}$</span></p><p class="math-container">\[   L_{obs}(\hat{u}) = \sum_{t=1}^{T} \sum_{i=1}^{d} \left(y_{i,t}-\hat{u}_{i,t}\right)^{T} \Sigma_{obs}^{-1} \left(y_{i,t}-\hat{u}_{i,t}\right)\]</p><p>The process error term has the same structure but compares the UDE model predictions <span>$F(\hat{u}_t,t,\theta)$</span> to the estimated states <span>$\hat{u}_{i,t+1}$</span></p><p class="math-container">\[   L_{proc}(\hat{u},\theta) = \sum_{t=1}^{T} \sum_{i=1}^{d} \left(\hat{u}_{i,t+1} - F(\hat{u}_t,t,\theta)\right)^{T} \Sigma_{proc}^{-1}\left(\hat{u}_{i,t+1} - F(\hat{u}_t,t,\theta)\right)\]</p><h3 id="Marginal-likelihood"><a class="docs-heading-anchor" href="#Marginal-likelihood">Marginal likelihood</a><a id="Marginal-likelihood-1"></a><a class="docs-heading-anchor-permalink" href="#Marginal-likelihood" title="Permalink"></a></h3><p>The marginal likelihood calculates the likelihood of the data <span>$y_t$</span> given the UDE model parameters <span>$\theta$</span> by estimating the state variables and the associated uncertainty. This requires distributional assumptions about the observation and process errors. As with the conditional likelihood, our implementation assumes these distributions are multivariate normal. However, the marginal likelihood only requires the user to provide the observaiton error matrix <span>$\Sigma_{obs}$</span> because the process errors <span>$\Sigma_{obs}$</span> are estimated as part of the model training routine.</p><p>Given these distributional assumptions, the likelihood is calculated by integrating over the distribution of the states <span>$u_t$</span> to get a quantity that only depends on the data <span>$y_t$</span> and the parameters <span>$\theta$</span>. We approximate the distribution of the state variables <span>$u_t$</span> using the <a href="chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://groups.seas.harvard.edu/courses/cs281/papers/unscented.pdf">unsented kalman filter algorithm</a>. A detailed description of the algorithm can be found in the proceeding link; the following description focuses on explaining how we use the algorithm to calculate the likelihood.</p><p>The algorithm approximates the distribution of the state variables <span>$u_t$</span> at each time step with a multivariate normal distribution with mean <span>$\hat{u}_t$</span> and covariance <span>$\Sigma_{u,t}$</span>. The values of <span>$\hat{u}_t$</span> and <span>$\Sigma_{u,t}$</span> are calcualted by an iterative process that starts with an inital estimate of the mean <span>$\hat{u}_0$</span> and covariance <span>$\Sigma_{u,0}$</span> at the time of the first observation. The estimates at the subsequent time steps are calculated by iteratively applying a twp step process. First, the initial estimate <span>$\hat{u}_{t}$</span> and  <span>$\Sigma_{u,t}$</span> is updated by conditioning on the observaiton <span>$y_t$</span>. Because we assume the initial distirubtion of <span>$u_{t}$</span> and the observaiton erros are multivariate normal this update step has a close form <a href="https://en.wikipedia.org/wiki/Kalman_filter">solution</a>, appying these fomulas yields updated estimates <span>$\hat{u}_{t}`$</span> and  <span>$\Sigma_{u,t}`$</span>. The next uses the UDE model for forecast the value state variables in the next time step <span>$\hat{u}_{t+1}$</span> and uses the unscented transform to propagate uncertainty through the UDE model. This error propogation step yields an estimate of the uncertianty accounting for the deterministic component of the dynamics  <span>$Cov[\hat{u}_t]$</span>. The final unceritnaty estimate is the propogated uncertainty plus the process errors <span>$\Sigma_{u,t+1} = Cov[\hat{u}_t] + \Sigma_{proc}$</span>.</p><p>Given our approximation of the states <span>$u_t$</span> as multivariate normal, the distribution of <span>$y_t$</span> is the sum of two multivariate normal random variables (the state estimates <span>$u_t$</span> and the observation errors <span>$\epsilon_{t}$</span>). Therefore, the marginal likelihood is a multivariate normal with mean <span>$u_t$</span> and covariance <span>$\Sigma_{u,t} + \Sigma_{obs}$</span>. Taking the log and summing over each data point in the time series yields the marginal likelihood function of the model.</p><p class="math-container">\[L(\theta,\Sigma_{proc}) = \sum_{t=1}^{T} (y_t - \hat{u}_t)^{T} (\Sigma_{u,t} + \Sigma_{obs})^{-1} (y_t - \hat{u}_t) - 1/2 log(|(\Sigma_{u,t} + \Sigma_{obs})|) - d/2log(2\pi).\]</p><p>where <span>$|\Sigma|$</span> is the determiniant of the matrix <span>$\Sigma$</span> and <span>$\Sigma^{-1}$</span> is the matrix inverse.</p><h3 id="Implementation-2"><a class="docs-heading-anchor" href="#Implementation-2">Implementation</a><a class="docs-heading-anchor-permalink" href="#Implementation-2" title="Permalink"></a></h3><p>The state-space loss functions can be accessed through the <code>train!</code> function by setting the <code>loss_function</code> keyword argument to <code>&quot;conditional likelihood&quot;</code> or <code>&quot;marginal likelihood&quot;</code>. The user can also provide a value for the regularization weight and set the process and observaiton error matrices using the <code>loss_options</code> argument. The process errors are set using the <code>process_error</code> key and observaiton errors using the <code>observation_error</code> key. The user can supply a <code>Float</code>, a vector of length d or a positive definite d<span>$\times$</span>d matrix. If a <code>Float</code> is provided, the error matrix will use that value along the diagonal and set all covariance terms to zero. If a vector is provided, it will be used as the diaganol of the matrix with all other terms equal to zero, and if a matrix is provided, it will be used as the full error covariance matrix.</p><pre><code class="language-julia hljs"># Conditional likelihood
train!(model;
       loss_function = &quot;conditional likelihood&quot;,
       regularization_weight = 0.0,
       loss_options = (process_error = 0.025,observation_error = 0.025)
   )


# Marginal likelihood
train!(model;
       loss_function = &quot;marginal likelihood&quot;,
       regularization_weight = 0.0,
       loss_options = (process_error = 0.025,observation_error = 0.025)
   )</code></pre><p>Note that if only one value is provided to <code>loss_options</code> it needs to be followed by a comma (e.g. <code>loss_options=(process_error = 0.025,)</code>)</p><h2 id="Shooting-loss-function"><a class="docs-heading-anchor" href="#Shooting-loss-function">Shooting loss function</a><a id="Shooting-loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Shooting-loss-function" title="Permalink"></a></h2><p>The shooting loss function jointly estimates the initial conditions <span>$u_0$</span> and the UDe model parameters <span>$\theta$</span> by numerically solving the UDE model starting <span>$u_0$</span> over the full length of the training data set to get a simulated trajectory <span>$\hat{u}(t)$</span>. The loss is calculated by comparing the simulated trajectory to the data set with the mean squared error</p><p class="math-container">\[   L(u_0,\theta)= \frac{1}{d*T} \sum_{t=0}^{T} \sum_{i=1}{d}(y_{i,t} - \hat{u}_i(t))^2.\]</p><p>This method can work for data sets with relatively smooth changes over time but is highly susceptible to getting stuck at local minimum solutions on data sets with oscillations. This method is totally unsuitable for systems with chaotic dynamics because of the sensitivity of the simulation trajectories to the initial conditions and model parameters.</p><h3 id="Implementation-3"><a class="docs-heading-anchor" href="#Implementation-3">Implementation</a><a class="docs-heading-anchor-permalink" href="#Implementation-3" title="Permalink"></a></h3><p>The shooting loss is accessed through the <code>train!</code> function by setting <code>loss_function = &quot;shooting&quot;</code> The regualrization weight can be set, but there are no additional arguments for this method.</p><pre><code class="language-julia hljs">train!(model;
       loss_function = &quot;shooting&quot;,
       regularization_weight = 0.0
   )</code></pre><h2 id="Multiple-shooting-loss-function"><a class="docs-heading-anchor" href="#Multiple-shooting-loss-function">Multiple shooting loss function</a><a id="Multiple-shooting-loss-function-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-shooting-loss-function" title="Permalink"></a></h2><p>The multiple shooting loss function tries to solve the issues with the shooting loss function by breaking that data set up into <span>$k$</span> segments. The training routine estimates a set of initial conditions <span>$u_{\tau}$</span> corresponding to the initial time point in each segment of the data set. The solution of the UDE model is solved numerically over each interval to create a set of <span>$k$</span> simulated trajectories associated with each starting point <span>$\hat{u}_k(t)$</span>.  The loss is calculated by comapring</p><p class="math-container">\[   L(\{u\}_{\tau},\theta)= \frac{1}{d*T} \sum_{t=0}^{T} \sum_{i=1}{d}(y_{i,t} - \hat{u}_{\tau,i}(t))^2.\]</p><p>This approach can help remove the local minimum solutions that plague the shooting loss function, provided a large enough number of segments <span>$k$</span> are chosen.</p><h3 id="Implementation-4"><a class="docs-heading-anchor" href="#Implementation-4">Implementation</a><a class="docs-heading-anchor-permalink" href="#Implementation-4" title="Permalink"></a></h3><p>The shooting loss is accessed through the <code>train!</code> function by setting <code>loss_function = &quot;multiple shooting&quot;</code> The regualrizaiton weight can be set using the  <code>regularization_weight</code> argument, and the number of data point spaned by each prediction interval is set using <code>loss_options = (pred_length = n,)</code>. The default value of pred_length is five</p><pre><code class="language-julia hljs">train!(model;
       loss_function = &quot;multiple shooting&quot;,
       regularization_weight = 0.0,
       loss_options = (pred_length = 5,)
   )</code></pre><h2 id="ADAM-optimizer"><a class="docs-heading-anchor" href="#ADAM-optimizer">ADAM optimizer</a><a id="ADAM-optimizer-1"></a><a class="docs-heading-anchor-permalink" href="#ADAM-optimizer" title="Permalink"></a></h2><p>The (Adam)[chrome-extension://efaidnbmnnnibpcajpcglclefindmkaj/https://arxiv.org/pdf/1412.6980] optimizer is a gradient descent algorithm that has two parameters, <code>step_size</code> and  <code>maxiter</code>. The defaults for these parameters are set to values that perform well with each loss function. Increasing the maximum number of iterations <code>maxiter</code> often improves model fits.</p><pre><code class="language-julia hljs">train!(model;
       optimizer = &quot;ADAM&quot;,
       verbose = true,
       optim_options = (step_size = 0.05, maxiter = 500)
   )</code></pre><h2 id="BFGS-optimizer"><a class="docs-heading-anchor" href="#BFGS-optimizer">BFGS optimizer</a><a id="BFGS-optimizer-1"></a><a class="docs-heading-anchor-permalink" href="#BFGS-optimizer" title="Permalink"></a></h2><p>The L-BFGS is an alternative method that uses approximate second-order information to minimize the loss function. This method can improve model fits when compared to Adam but can also lead to overfitting if the neural network is not sufficiently regularized</p><pre><code class="language-julia hljs">train!(model;
       optimizer = &quot;BFGS&quot;,
       verbose = true,
       optim_options = (initial_stepnorm = 0.01,)
   )</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Models/">« Model Constructors</a><a class="docs-footer-nextpage" href="../ModelTesting/">Model performance »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.3.0 on <span class="colophon-date" title="Monday 7 July 2025 20:24">Monday 7 July 2025</span>. Using Julia version 1.10.10.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
